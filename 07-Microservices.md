# MICROSERVICES 

## Microservices Fundamentals

**#. What are microservices and how do they differ from monolithic architecture?**

Microservices is an architectural style where an application is composed of small, independent services that communicate over network. Each service focuses on a specific business capability, can be developed and deployed independently, and may use different technologies. **Monolithic**: single codebase, all features in one application, shared database, deploy entire app for any change, scales as a unit, one technology stack, tight coupling. **Microservices**: multiple codebases, each service separate application, database per service, deploy services independently, scale services individually, polyglot (different tech per service), loose coupling. **Example**: E-commerce monolith has user management, orders, payments, inventory in one app. Microservices has separate user-service, order-service, payment-service, inventory-service. Benefits: scalability, resilience, faster development. Challenges: complexity, distributed systems issues, operational overhead.

**#. What are the key characteristics of microservices architecture?**

Key characteristics: **1) Single Responsibility** - each service does one thing well, focused on business capability. **2) Independently Deployable** - deploy without affecting other services. **3) Decentralized Data Management** - each service owns its database. **4) Failure Isolation** - failure in one service doesn't crash entire system. **5) Technology Diversity** - different services can use different tech stacks. **6) Organized Around Business Capabilities** - services aligned with business domains, not technical layers. **7) Smart Endpoints, Dumb Pipes** - business logic in services, communication is simple (REST, messaging). **8) Automated Deployment** - CI/CD essential for managing many services. **9) Design for Failure** - assume services will fail, build resilience. **10) Observable** - extensive logging, monitoring, tracing. These characteristics enable scalability, resilience, and agility but require sophisticated infrastructure and practices.

**#. What are the advantages of microservices?**

Key advantages: **1) Scalability** - scale individual services based on demand, not entire app. **2) Technology Flexibility** - use best tool for each job, experiment with new tech. **3) Faster Development** - small teams work independently, parallel development. **4) Easier Deployment** - deploy individual services, less risk than deploying monolith. **5) Fault Isolation** - failure contained to one service, others continue working. **6) Better Resource Utilization** - allocate resources per service needs. **7) Team Autonomy** - teams own services end-to-end. **8) Easier to Understand** - small codebases easier to maintain than large monolith. **9) Business Agility** - faster feature delivery, easier to pivot. **10) Improved CI/CD** - smaller deployments, faster pipelines. Real-world benefits: Netflix scaled from monolith to hundreds of microservices, handles millions of requests. Amazon teams can deploy independently thousands of times per day.

**#. What are the challenges of microservices?**

Key challenges: **1) Complexity** - distributed systems are inherently complex. **2) Network Latency** - service calls over network slower than in-process. **3) Data Consistency** - no ACID transactions across services, eventual consistency. **4) Testing** - integration testing harder with many services. **5) Debugging** - tracing requests across services difficult. **6) Operational Overhead** - many services to deploy, monitor, manage. **7) Service Communication** - handling failures, timeouts, retries. **8) Security** - more attack surface, service-to-service authentication. **9) Versioning** - managing API versions across services. **10) Data Management** - joining data across services. **11) Initial Investment** - infrastructure (orchestration, monitoring, CI/CD). **12) Team Coordination** - services must work together despite autonomy. Microservices not suitable for small teams or simple apps. Start with monolith, move to microservices when scaling challenges arise.

**#. When should you use microservices vs monolithic architecture?**

**Use Monolithic when**: small team (< 10 developers), simple domain, MVP/startup (speed to market), limited resources, well-understood requirements, team lacks distributed systems expertise. **Use Microservices when**: large team (multiple teams), complex domain (many bounded contexts), scaling needs (different components have different load), need technology diversity, frequent deployments, mature DevOps practices in place, independent service evolution needed. **Migration path**: start with well-structured monolith (modular), extract services when needed (hotspots, different scaling needs, team boundaries). **Red flags for microservices**: small team trying microservices, no automation infrastructure, premature optimization, cargo-culting (doing it because others do). **Success factors for microservices**: DevOps culture, automation (CI/CD, infrastructure), monitoring/observability, experienced team. Don't start with microservices - grow into them when monolith pain points emerge.

**#. What is Domain-Driven Design (DDD) and how does it relate to microservices?**

DDD is an approach to software development focusing on complex domain logic. Key concepts: **Bounded Context** - explicit boundary within which a domain model applies. Each microservice typically represents one bounded context. **Ubiquitous Language** - shared language between developers and domain experts. **Entities** - objects with identity that persists over time. **Value Objects** - objects defined by attributes, no identity. **Aggregates** - cluster of entities/value objects treated as unit. **Domain Events** - something that happened in domain. **Relationship to microservices**: DDD helps identify service boundaries - each bounded context becomes a microservice. Prevents wrong decomposition. Example: E-commerce has contexts: Catalog (product info), Cart (shopping cart), Orders (order processing), Payments (payment processing). Each becomes a service. DDD provides language and patterns for designing microservices properly. Without DDD, services often split incorrectly (too fine-grained or wrong boundaries).

**#. What is the concept of bounded context in microservices?**

Bounded Context is a central DDD concept - explicit boundary within which a domain model is defined and applicable. Each microservice should represent one bounded context. **Example**: in e-commerce, "Customer" means different things in different contexts. In **Sales context** (customer-service), Customer has order history, preferences, loyalty points. In **Support context** (support-service), Customer has tickets, contact info. In **Shipping context** (logistics-service), Customer is delivery address. Same real-world concept, different models. Each bounded context has its own model without pollution from others. **Benefits**: clear service boundaries, reduces coupling, teams can evolve models independently, prevents god objects spanning entire system. **Anti-pattern**: sharing database or domain models across services violates bounded context. Each service owns its model and data. Bounded context is key to proper microservices decomposition.

**#. Explain the database per service pattern.**

Database per service means each microservice has its own database, not shared with other services. Other services cannot access database directly - only through service's API. **Benefits**: **1) Loose Coupling** - services independent, can change schema without affecting others. **2) Technology Choice** - use SQL for one service, NoSQL for another. **3) Scalability** - scale database per service needs. **4) Isolation** - failure in one database doesn't affect others. **Challenges**: **1) Data Consistency** - no ACID transactions across services, use Saga pattern. **2) Joins** - can't join across databases, use API composition or CQRS. **3) Data Duplication** - may need to replicate some data. **Implementation**: physically separate databases, or separate schemas, or logical separation with access control. **Example**: order-service uses PostgreSQL, product-service uses MongoDB, user-service uses MySQL. Critical for true microservices independence. Shared database creates tight coupling and defeats microservices benefits.

**#. How do you decompose a monolith into microservices?**

Decomposition strategies: **1) By Business Capability** - identify business capabilities (User Management, Orders, Payments), create service per capability. **2) By Subdomain** - use DDD bounded contexts as service boundaries. **3) By Team** - Conway's Law - services mirror team structure. **Process**: **a) Identify Seams** - find natural boundaries in monolith (modules, packages). **b) Prioritize** - start with independently changeable, high-value, or scaling-constrained components. **c) Extract Gradually** - strangler pattern, run both in parallel, gradually move traffic. **d) Data Migration** - separate databases, replicate data initially. **e) Test** - comprehensive testing at each step. **Patterns**: **Strangler Fig** - gradually replace monolith functionality. **Branch by Abstraction** - introduce abstraction, swap implementations. **Anti-patterns**: big bang (rewrite everything), too fine-grained (nanoservices), wrong boundaries. **Example**: extract payment-service first (clear boundary, external dependency), then order-service, then others. Decomposition is iterative - expect to refine boundaries.

**#. What is Conway's Law and its relevance to microservices?**

Conway's Law: "Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations." Simply: system architecture mirrors organizational structure. **Relevance to microservices**: service boundaries should align with team boundaries. Each team owns one or few services end-to-end. **Example**: if you have separate frontend, backend, database teams, you get 3-tier architecture. If you have cross-functional teams around business capabilities (Orders Team, Payments Team), you get microservices aligned with business. **Inverse Conway Maneuver**: deliberately reorganize teams to achieve desired architecture. Want microservices? Create small cross-functional teams owning business capabilities. **Benefits**: reduces coordination overhead, clear ownership, faster development. **Anti-pattern**: single team owns all services (loses autonomy benefit), or service boundaries don't match team boundaries (coordination overhead). Successful microservices organizations structure teams around services.

**#. What are the different communication patterns in microservices?**

Two main types: **Synchronous** and **Asynchronous**. **Synchronous**: **1) REST/HTTP** - most common, request-response, easy to understand. **2) gRPC** - high performance, binary protocol, strongly typed. Service waits for response, blocking. **Asynchronous**: **3) Message Queues** - RabbitMQ, AWS SQS, point-to-point messaging. **4) Event Streaming** - Kafka, services publish events, others subscribe. **5) Pub/Sub** - Google Pub/Sub, message broadcast to subscribers. Non-blocking, eventual consistency. **Point-to-point vs Broadcast**: Point-to-point (queues) - one consumer gets message. Broadcast (pub/sub, events) - all subscribers get message. **Choosing**: Use synchronous for queries (need immediate response), use asynchronous for commands/events (fire-and-forget, decoupling). **Example**: GET /users/123 (sync REST), Order Created event (async Kafka). Hybrid approach common - mix based on use case.

**#. What is service discovery and why is it needed?**

Service discovery enables services to find each other dynamically. In microservices, service instances come and go (scaling, failures, deployments), IP addresses change. Hardcoding URLs doesn't work. **Two types**: **Client-side discovery** - client queries registry for service locations, chooses instance, makes request. Example: Netflix Eureka. Client has load balancing logic. **Server-side discovery** - load balancer queries registry, routes request. Example: Kubernetes Service, AWS ELB. Client doesn't need registry logic. **Components**: **1) Service Registry** - database of service instances (Consul, Eureka, etcd). **2) Registration** - services register on startup, deregister on shutdown. **3) Health Checks** - registry monitors service health, removes unhealthy instances. **4) DNS** - some registries provide DNS interface. **Benefits**: dynamic environments, auto-scaling, zero-downtime deployments. Modern platforms (Kubernetes) have built-in service discovery.

**#. Explain client-side vs server-side service discovery.**

**Client-side discovery**: client responsible for determining service instance location. **Flow**: 1) Service instances register with registry. 2) Client queries registry for available instances. 3) Client uses load balancing algorithm to select instance. 4) Client makes request directly to instance. **Pros**: simple for server, client controls load balancing, fewer network hops. **Cons**: client more complex, load balancing logic in each client, coupling to registry. **Examples**: Netflix Eureka, HashiCorp Consul with client libraries. **Server-side discovery**: load balancer handles discovery. **Flow**: 1) Service instances register with registry. 2) Client makes request to load balancer. 3) Load balancer queries registry. 4) Load balancer routes to instance. **Pros**: simpler clients, centralized load balancing, language-agnostic. **Cons**: additional hop (latency), load balancer can be bottleneck. **Examples**: Kubernetes Service, AWS ELB, NGINX with Consul. Server-side is more common - simpler for clients, platform handles complexity.

**#. What is an API Gateway in microservices?**

API Gateway is a server acting as single entry point for client requests, routing to appropriate microservices. **Responsibilities**: **1) Routing** - routes requests to correct service based on URL. **2) Authentication** - validates JWT tokens, API keys. **3) Rate Limiting** - enforces rate limits per client. **4) Request/Response Transformation** - modifies data format. **5) Protocol Translation** - REST to gRPC, WebSocket. **6) API Composition** - aggregates responses from multiple services. **7) Caching** - caches responses to reduce load. **8) Logging/Monitoring** - centralized logging of all requests. **9) CORS handling**. **10) SSL termination**. **Benefits**: simplifies clients (one endpoint), decouples clients from service topology, handles cross-cutting concerns. **Examples**: Kong, AWS API Gateway, Netflix Zuul, Spring Cloud Gateway. **Anti-pattern**: God gateway - don't put business logic in gateway, keep it thin. Gateway is infrastructure, not domain logic.

**#. What is the Backend for Frontend (BFF) pattern?**

BFF creates separate backend service for each client type (web, mobile, desktop, IoT). Each BFF tailored to specific client needs. **Problem**: single API doesn't fit all clients well. Mobile needs less data (bandwidth), different format. Web needs more. Desktop needs different features. **Solution**: web-bff for web client, mobile-bff for mobile client, each optimized for its client. **Benefits**: **1) Optimized Responses** - mobile-bff returns less data, optimized format. **2) Client Autonomy** - frontend teams control their BFF. **3) No Generic API** - don't compromise between client needs. **4) Security** - different auth requirements per client. **Example**: mobile-bff → product name, image thumbnail. web-bff → product name, description, multiple images, reviews. **Implementation**: BFFs sit between API Gateway and microservices. BFF aggregates calls to multiple services, transforms data. **Ownership**: frontend team owns BFF, can deploy independently. BFF is specialized API Gateway for specific client.

**#. What is the Strangler Fig pattern?**

Strangler Fig pattern gradually replaces legacy system by incrementally migrating functionality to new system. Named after strangler fig tree that grows around host tree. **Process**: **1) Identify Functionality** - choose feature to migrate. **2) Build New Service** - implement in microservice. **3) Route Traffic** - use facade/proxy to route some traffic to new service. **4) Run in Parallel** - both old and new handle traffic, compare results. **5) Increase Traffic** - gradually shift more traffic to new service. **6) Remove Old** - when confident, delete old code. **7) Repeat** - migrate next feature. **Benefits**: low risk (gradual), can validate each step, no big bang, continuous delivery. **Implementation**: use API Gateway or reverse proxy to route requests. Feature flags to control traffic percentage. **Example**: migrate payment processing first (isolated), then checkout, then product catalog. Eventually entire monolith replaced. Recommended approach for monolith to microservices migration.

**#. What is the Sidecar pattern?**

Sidecar pattern deploys helper component alongside main service in same host/pod. Sidecar provides supporting features without modifying main service. **Common sidecars**: **1) Service Mesh Proxy** - Envoy, handles service-to-service communication, load balancing, retries, circuit breaking. **2) Logging Agent** - Fluentd, collects logs, ships to central system. **3) Monitoring Agent** - Prometheus exporter, exposes metrics. **4) Security** - TLS termination, authentication. **Benefits**: separation of concerns (main service focuses on business logic), technology-agnostic (sidecar in any language), reusable (same sidecar for all services), platform features without code changes. **Example**: in Kubernetes, pod has two containers - main service container and Envoy sidecar. Envoy handles all network communication, retries, observability. Main service just calls localhost. **Service Mesh**: Istio uses sidecar pattern extensively. Every service has Envoy sidecar injected automatically. Critical pattern for platform capabilities in microservices.

**#. What is the Circuit Breaker pattern?**

Circuit Breaker prevents cascading failures by detecting failures and stopping calls to failing service. Like electrical circuit breaker. **States**: **1) Closed** - normal operation, requests pass through. If failures exceed threshold (e.g., 50% in 10 sec), opens. **2) Open** - requests fail immediately without calling service, returns fallback response or error. After timeout (e.g., 30 sec), transitions to half-open. **3) Half-Open** - tries request to see if service recovered. Success closes circuit, failure reopens. **Benefits**: fail fast (no waiting for timeout), prevents resource exhaustion (thread pools), gives failing service time to recover, improves user experience (immediate fallback vs hanging). **Implementation**: Netflix Hystrix (deprecated), Resilience4j, Istio. **Configuration**: failure threshold (5 failures), timeout (30 sec), success threshold for half-open (2 successes). **Fallback**: return cached data, default value, or error. **Example**: payment-service calls external payment API. API fails, circuit opens, payment-service returns "payment unavailable" immediately.

**#. What is the Saga pattern for distributed transactions?**

Saga manages distributed transactions across microservices using sequence of local transactions with compensating transactions for rollback. No ACID across services. **Two types**: **Choreography** - services coordinate through events, no central controller. Each service knows what to do after receiving event, publishes next event. **Orchestration** - central coordinator (saga orchestrator) tells services what to do, handles flow. **Example - Order Saga**: 1) Order Service creates order. 2) Payment Service charges card. 3) Inventory Service reserves items. 4) Shipping Service creates shipment. If Shipping fails: compensate - Inventory releases items, Payment refunds, Order cancels. **Choreography**: OrderCreated event → Payment charges → PaymentCompleted event → Inventory reserves → InventoryReserved event → Shipping creates shipment. **Orchestration**: Saga Orchestrator calls Payment, then Inventory, then Shipping. On failure, calls compensate actions. **Use orchestration** for complex flows, better observability. **Use choreography** for simple flows, less coupling. Saga is answer to "no distributed transactions in microservices."

**#. What is eventual consistency in microservices?**

Eventual consistency means data across services will become consistent eventually, not immediately. Contrasts with strong consistency (immediate). In microservices with database per service, updating multiple services atomically is impossible. **Example**: user updates profile. user-service updates immediately. order-service still has old name until event processed (seconds later). Temporarily inconsistent, eventually consistent. **Why needed**: distributed systems (CAP theorem - can't have both consistency and availability during partition), performance (synchronous updates across services slow), scalability (async messaging scales better). **Techniques**: **1) Event-driven** - publish events, services update themselves. **2) Saga pattern** - sequence of local transactions. **3) CQRS** - separate read/write models. **Trade-offs**: simpler code vs user confusion (seeing old data), better performance vs complexity (handling inconsistency). **When acceptable**: user profiles, inventory (slightly stale okay), product catalogs. **When not**: financial transactions (need strong consistency), real-time bidding. Most microservices embrace eventual consistency for scalability.

## Inter-Service Communication

**#. What is REST vs gRPC for microservice communication?**

**REST**: HTTP-based, JSON payloads, human-readable, widely supported, text protocol. **gRPC**: HTTP/2-based, Protocol Buffers (binary), strongly-typed, high performance, language-agnostic. **REST advantages**: simple, readable, browser-compatible, debugging easy (curl, Postman), ubiquitous. **REST disadvantages**: verbose (JSON overhead), slow serialization, no type safety, no streaming. **gRPC advantages**: fast (binary, HTTP/2), efficient (smaller payloads), type safety (protobuf), streaming (bidirectional), code generation (clients/servers from protobuf). **gRPC disadvantages**: not browser-compatible (without proxy), binary (harder debugging), learning curve, less ubiquitous. **Use REST for**: public APIs, browser clients, simple services, debugging-heavy environments. **Use gRPC for**: internal service-to-service, performance-critical, large payloads, streaming. **Real-world**: Google, Netflix use gRPC internally, REST for public APIs. Hybrid common - REST for external, gRPC for internal.

**#. What is message-based communication in microservices?**

Message-based communication uses message brokers for asynchronous communication. Services send messages to broker, other services consume from broker. **Benefits**: **1) Decoupling** - sender doesn't know consumers. **2) Async** - non-blocking, sender continues immediately. **3) Resilience** - broker persists messages, retry on failure. **4) Scalability** - multiple consumers, load balancing. **5) Temporal Decoupling** - consumers don't need to be online. **Message Brokers**: **RabbitMQ** - AMQP protocol, queues, exchanges. **Apache Kafka** - distributed event streaming, high throughput, event log. **AWS SQS** - managed queues. **Google Pub/Sub** - managed pub/sub. **Patterns**: **1) Command** - one consumer processes message (queue). **2) Event** - multiple consumers react (pub/sub). **When to use**: events (order created), commands (send email), background processing, integration between services. **Example**: Order Service publishes OrderCreated message. Inventory Service consumes (reserves items), Email Service consumes (sends confirmation). Decoupled, resilient.

**#. Explain synchronous vs asynchronous communication.**

**Synchronous (Request-Response)**: caller waits for response, blocking. Examples: REST, gRPC. **Flow**: Service A calls Service B, blocks until response, continues. **Pros**: simple to understand, immediate response, error handling straightforward, transactional. **Cons**: tight temporal coupling (both must be available), cascading failures, latency accumulates, resource blocking (threads waiting). **Use for**: queries (need immediate data), transactional operations. **Asynchronous (Fire-and-Forget)**: caller doesn't wait, continues immediately. Examples: messaging, events. **Flow**: Service A sends message to broker, continues. Service B processes later. **Pros**: decoupling (temporal and spatial), better scalability, resilience (retry, dead-letter), handles spikes. **Cons**: complexity (message broker, idempotency), eventual consistency, harder debugging, no immediate response. **Use for**: events (domain events), commands (send email), background tasks. **Reality**: hybrid - queries synchronous, updates asynchronous. Order Service gets product info (sync REST), publishes OrderCreated event (async Kafka).

**#. What is event-driven architecture in microservices?**

Event-driven architecture uses events (state changes) as primary communication mechanism. Services publish events when something happens, other services subscribe and react. **Components**: **1) Event Producers** - publish events (Order Service publishes OrderCreated). **2) Event Consumers** - subscribe to events (Inventory Service subscribes). **3) Event Broker** - Kafka, RabbitMQ, distributes events. **Event types**: **Domain Events** - something happened in domain (UserRegistered). **Integration Events** - for service integration (OrderShipped). **Pattern**: **1) Event Notification** - minimal info, consumers query for details. **2) Event-Carried State Transfer** - full state in event, consumers don't need query. **Benefits**: loose coupling (producers don't know consumers), scalability (add consumers without affecting producers), audit trail (event log), time travel (replay events). **Challenges**: eventual consistency, debugging (tracing across events), message ordering, duplicate handling. **Use for**: reactive systems, CQRS, event sourcing. Example: E-commerce - OrderCreated → Inventory reserves, Email sends confirmation, Analytics updates dashboard. All decoupled.

**#. What is Apache Kafka and when do you use it?**

Kafka is distributed event streaming platform. Not just message broker - distributed, persistent, high-throughput event log. **Key concepts**: **Topics** - categories of events (orders, payments). **Partitions** - topics split for parallelism, ordering within partition. **Producers** - publish events. **Consumers** - read events. **Consumer Groups** - multiple consumers share work, each message consumed once per group. **Brokers** - Kafka servers. **Features**: **1) Persistent** - events stored on disk, can replay. **2) High Throughput** - millions of events/sec. **3) Scalable** - add brokers, partitions. **4) Fault-Tolerant** - replication across brokers. **5) Event Sourcing** - store all events as log. **Use cases**: **1) Event Streaming** - real-time data pipelines. **2) Service Integration** - microservices communication. **3) Event Sourcing** - store domain events. **4) Log Aggregation** - collect logs from services. **5) Stream Processing** - process events in real-time (Kafka Streams). **When to use**: high throughput, event history needed, multiple consumers. **When not**: simple request-response, low volume, no need for history (use RabbitMQ).

**#. What is the difference between message queue and publish-subscribe?**

Both are messaging patterns but differ in delivery. **Message Queue (Point-to-Point)**: one message, one consumer. Producers send to queue, only one consumer receives and processes. **Example**: RabbitMQ queue with multiple consumers - message goes to one consumer (load balanced). **Use for**: commands (send email, process payment), work distribution, load balancing. Once consumed, message gone. **Publish-Subscribe (Pub/Sub)**: one message, multiple consumers. Publishers publish to topic, all subscribers receive copy. **Example**: Kafka topic with multiple consumer groups - each group gets copy. **Use for**: events (OrderCreated), notifications (broadcast), fan-out. **Key difference**: Queue - competing consumers (one gets message). Pub/Sub - multiple independent consumers (all get message). **Hybrid**: Kafka with consumer groups - within group, queue behavior (one consumer). Across groups, pub/sub (all groups get message). Choose based on semantics: command (queue) vs event (pub/sub).

**#. How do you handle service-to-service authentication?**

Authentication between microservices ensures services trust each other. **Methods**: **1) Mutual TLS (mTLS)** - both client and server present certificates, verify each other. Service mesh (Istio) automates this. **2) JWT Tokens** - service gets JWT from auth service, includes in requests to other services. Other services validate JWT signature. **3) API Keys** - each service has API key, includes in requests. Simple but less secure. **4) OAuth 2.0 Client Credentials** - service gets access token from OAuth server, uses for requests. **Best practice**: **1) Use mTLS** - strongest, automated by service mesh. **2) Short-lived tokens** - rotate frequently. **3) Service Identities** - each service has unique identity. **4) Network Segmentation** - private network for services. **5) Zero Trust** - don't trust network, authenticate everything. **Implementation**: Istio with mTLS, services don't handle auth (sidecar does). Or use JWT propagation - API Gateway validates user token, creates service token, services pass along. Avoid: trusting all internal traffic, shared secrets, no authentication.

**#. What is service mesh and how does it help?**

Service mesh is dedicated infrastructure layer for service-to-service communication. Adds capabilities without changing application code. **Architecture**: data plane (sidecars - Envoy proxies alongside services) and control plane (manages/configures proxies). **Capabilities**: **1) Traffic Management** - load balancing, routing, retries, timeouts, circuit breaking. **2) Security** - mTLS between services, authentication, authorization. **3) Observability** - metrics, distributed tracing, logs. **4) Resilience** - fault injection, rate limiting. **Popular**: Istio (most features, complex), Linkerd (simpler, lightweight), Consul Connect. **Benefits**: uniform handling across services (regardless of language), no code changes (sidecar handles), centralized policy, rich observability. **Drawbacks**: complexity, operational overhead, latency (proxy hop), resource usage (sidecar per pod). **When to use**: many services (10+), polyglot environment, need advanced traffic management, compliance requirements. **When not**: few services, simple communication, resource-constrained. Service mesh is powerful but adds complexity - adopt when benefits outweigh costs.

**#. What is Istio and what problems does it solve?**

Istio is open-source service mesh providing traffic management, security, and observability. **Architecture**: **1) Data Plane** - Envoy sidecars next to services, intercept all traffic. **2) Control Plane** - Istiod configures proxies, manages certificates. **Features**: **Traffic Management** - intelligent routing (A/B, canary), load balancing, retries, timeouts, circuit breakers, fault injection. **Security** - automatic mTLS, authentication (JWT), authorization (RBAC). **Observability** - metrics (Prometheus), tracing (Jaeger), access logs. **Problems solved**: **1) Boilerplate** - no retry logic in code, Istio handles. **2) Polyglot** - same capabilities regardless of language. **3) Security** - mTLS without code changes. **4) Visibility** - metrics/tracing without instrumentation. **5) Traffic Control** - canary rollouts without code. **Example**: deploy new version, Istio routes 10% traffic to it (canary), monitors metrics, gradually increases or rolls back. All configuration, no code changes. **Trade-offs**: complexity (learning curve, debugging), resource overhead (sidecars), operational burden. Istio powerful for large microservices deployments.

**#. How do you implement request tracing across microservices?**

Distributed tracing tracks requests across multiple services. Essential for debugging microservices. **Concepts**: **Trace** - entire journey of request. **Span** - single operation (one service call), spans form tree. **Trace ID** - unique ID for entire request. **Span ID** - unique ID for each span. **Parent Span ID** - links spans. **How it works**: **1) Generate Trace ID** - API Gateway generates on first request. **2) Propagate** - include Trace ID in headers (X-B3-TraceId, traceparent), each service passes to next. **3) Create Spans** - each service creates span for its work, includes trace ID, span ID, parent span ID. **4) Send to Collector** - services send spans to tracing backend. **5) Visualize** - trace shows request flow, timing, errors. **Tools**: Jaeger, Zipkin, AWS X-Ray, Google Cloud Trace. **Standards**: OpenTelemetry (unified standard for tracing, metrics, logs). **Implementation**: use library (OpenTelemetry SDK), automatically instruments frameworks. Or service mesh (Istio) adds tracing without code changes. Include trace ID in logs for correlation.

**#. What is the Retry pattern and how do you implement it?**

Retry pattern automatically retries failed operations. Handles transient failures (network glitches, temporary service unavailability). **Strategy**: **1) Simple Retry** - retry N times with fixed delay. **2) Exponential Backoff** - delay increases exponentially (1s, 2s, 4s, 8s), with jitter (randomness) to avoid thundering herd. **3) Retry with Timeout** - give up after max time. **Configuration**: max attempts (3), initial delay (100ms), backoff multiplier (2x), max delay (30s), jitter (±25%). **Idempotency crucial**: retries must be safe to repeat. Use idempotency keys - client sends unique key, server deduplicates. **Which errors to retry**: network errors, 5xx server errors, timeouts. **Don't retry**: 4xx client errors (won't succeed), 409 conflicts. **Implementation**: libraries (Resilience4j, Polly), service mesh (Istio configures retry at proxy level). **Example**: order-service calls payment-service, network timeout, retry 3 times with exponential backoff. **Circuit Breaker + Retry**: retry for transient failures, circuit breaker for prolonged outages. Retry improves resilience but be careful - retry storms can overwhelm failing service.

**#. What is the Timeout pattern?**

Timeout pattern limits how long to wait for operation. Prevents indefinite waiting, releases resources. **Why needed**: service might be slow or hung, threads/connections tied up waiting, cascade failures (service A waits for B, B waits for C, all blocked). **Types**: **Connection timeout** - how long to establish connection. **Read timeout** - how long to wait for response after connection. **Request timeout** - total time for request. **Configuration**: set timeouts everywhere - HTTP clients, database queries, message consumers. **Values**: depends on operation - fast endpoint 1s, slow report 30s. **Implementation**: HTTP client libraries (set connectTimeout, readTimeout), Spring RestTemplate, gRPC deadlines. **Fallback**: on timeout, return default, cached data, or error. **Example**: order-service calls inventory-service with 5s timeout. If no response, returns "inventory unavailable" instead of hanging. **Best practices**: tune timeouts per endpoint, shorter than circuit breaker threshold, include in SLAs. **Avoid**: no timeout (hangs forever), too short (fails on normal operations), too long (delays failure detection). Timeouts + retries + circuit breakers provide resilience.

**#. What is the Bulkhead pattern?**

Bulkhead pattern isolates resources to prevent cascading failures. Like ship bulkheads - one compartment floods, others stay dry. **Isolation techniques**: **1) Thread Pools** - separate thread pool per dependency. Inventory-service calls use pool A (10 threads), payment-service calls use pool B (10 threads). Inventory failure exhausts pool A, pool B unaffected. **2) Connection Pools** - separate connection pool per database. **3) Semaphores** - limit concurrent calls. **4) Service Instances** - dedicated instances per critical function. **Benefits**: failure contained (one dependency doesn't starve resources), better resource management, protects critical functionality. **Example**: without bulkhead - order-service calls slow third-party API, all threads blocked waiting, can't process other requests. With bulkhead - third-party calls limited to 5 threads, other 20 threads handle regular requests. **Implementation**: Netflix Hystrix (deprecated), Resilience4j Bulkhead, manually with separate thread pools. **Trade-offs**: more complex, more resource overhead (separate pools). Use for critical services or unreliable dependencies.

**#. How do you handle message ordering and idempotency?**

**Message Ordering**: ensuring messages processed in correct order. **Challenges**: distributed systems don't guarantee order. **Solutions**: **1) Single partition** (Kafka) - messages to same partition ordered. Use user ID as partition key, all user events in order. **2) Sequence numbers** - include sequence number in message, consumer buffers, processes in order. **3) Timestamps** - use timestamps, process in order, but clock skew issues. **Trade-offs**: ordering limits parallelism. Often don't need strict ordering, eventual consistency sufficient. **Idempotency**: processing message multiple times has same effect as once. Essential because messaging systems deliver at-least-once. **Techniques**: **1) Idempotency keys** - unique ID per message, store processed IDs, skip duplicates. **2) Natural idempotency** - some operations inherently idempotent (set status=COMPLETED). **3) Database constraints** - unique constraints prevent duplicates. **Example**: OrderCreated event processed twice. With idempotency key, second attempt detected and skipped. Without, order created twice. **Implementation**: store processed message IDs in database/cache with TTL. Critical for reliable async communication.

**#. What is the Outbox pattern?**

Outbox pattern ensures reliable message publishing with database changes. **Problem**: order created in database, publish OrderCreated event. If database succeeds but publish fails, inconsistent state. Can't use distributed transaction. **Solution**: **1) Local Transaction** - in same transaction, insert order into orders table, insert event into outbox table. Atomic. **2) Message Relay** - separate process polls outbox table, publishes events, marks as published. Eventual consistency. **Flow**: Order Service → DB Transaction (insert order + insert to outbox) → commit → Message Relay reads outbox → publishes to Kafka → marks published. **Benefits**: atomicity (order and event together), reliability (events always published), at-least-once delivery. **Variants**: **Transaction Log Tailing** - read database transaction log (CDC - Change Data Capture) instead of outbox table. Tools: Debezium. **Implementation**: outbox table (id, aggregate_type, aggregate_id, event_type, payload, published). Relay (polling or CDC). **Trade-offs**: complexity, eventual consistency (slight delay), relay is critical component. Outbox pattern essential for reliable event-driven microservices.

## Data Management

**#. How do you manage transactions across microservices?**

Distributed transactions across services are challenging. ACID doesn't work. **Approaches**: **1) Avoid** - redesign boundaries, keep transactional data in one service. **2) Saga Pattern** - sequence of local transactions with compensating transactions. Choreography (event-driven) or orchestration (coordinator). **3) Two-Phase Commit (2PC)** - coordinator asks services to prepare, then commit. Blocking, not recommended for microservices. **4) Eventually Consistent** - accept temporary inconsistency. Example: order created but payment not yet processed. **5) Event Sourcing** - store events, rebuild state. **Saga Example**: create order → reserve inventory → charge payment. If payment fails: release inventory, cancel order (compensation). **Best practices**: prefer local transactions, design for idempotency, compensate instead of rollback, monitor saga state, timeouts for each step. **Real world**: most microservices use Saga or eventual consistency. Strong consistency when absolutely needed (rare). Embrace eventual consistency where acceptable.

**#. What is event sourcing?**

Event sourcing stores all changes as sequence of events instead of current state. Events are immutable, append-only log. **Concept**: don't store "order status = COMPLETED". Store OrderCreated, PaymentReceived, OrderShipped, OrderCompleted events. Current state derived by replaying events. **Benefits**: **1) Audit Trail** - complete history. **2) Temporal Queries** - what was state at any point? **3) Event Replay** - rebuild state, fix bugs, create new projections. **4) Event-Driven** - events already there for other services. **5) Debugging** - see what happened. **Challenges**: **1) Complexity** - learning curve. **2) Eventual Consistency** - read model behind write model. **3) Event Schema Evolution** - events immutable, versioning tricky. **4) Query** - can't query event log directly, need projections. **CQRS often paired**: write events (command), read from projection (query). **Use cases**: domain with rich history (banking, healthcare), audit requirements, complex domains. **Tools**: Axon Framework, Eventuate, Event Store DB. Example: bank account - store Deposited, Withdrawn events, balance = replay events.

**#. What is CQRS (Command Query Responsibility Segregation)?**

CQRS separates read and write operations using different models. **Traditional**: same model for read and write. Order object used for creating and querying. **CQRS**: **Command model** (write) - handles commands (CreateOrder), optimized for updates, normalized. **Query model** (read) - handles queries (GetOrder), optimized for reads, denormalized, can have multiple projections. **Flow**: client sends command → command handler validates, updates aggregate, publishes event → event handler updates read model → client queries read model. **Benefits**: **1) Separate Scaling** - scale reads and writes independently. **2) Optimized** - write model for consistency, read model for performance. **3) Multiple Read Models** - same data, different views (dashboard, reports). **4) Eventual Consistency** - embraced explicitly. **Challenges**: complexity, eventual consistency (read behind write), data duplication. **When to use**: read/write patterns very different, need different scalability, event sourcing. **When not**: simple CRUD, small scale. **Example**: e-commerce - write to relational DB, project to Elasticsearch for search, to data warehouse for analytics.

**#. How do you handle data consistency across microservices?**

Consistency models: **Strong consistency** (immediate) vs **Eventual consistency** (delayed). Microservices typically eventual. **Strategies**: **1) Saga Pattern** - coordinated local transactions with compensation. **2) Event-Driven** - publish events, services update their view. **3) CQRS** - separate write and read, accept read lag. **4) Distributed Lock** - coordinate with lock (Zookeeper), but reduces scalability. **5) Avoid** - redesign to not need cross-service consistency. **Example**: order-service creates order, publishes OrderCreated. inventory-service consumes event, reserves items (eventual). For seconds, states inconsistent. **Handling inconsistency**: **1) User Communication** - "processing...", "will be available shortly". **2) Compensating Actions** - if reservation fails later, cancel order. **3) Eventual Correction** - background jobs fix inconsistencies. **4) Timeouts** - if not consistent within X time, escalate. **Best practices**: design for idempotency, include timestamps, correlation IDs, monitor for stuck sagas. Most business processes tolerate eventual consistency (seconds/minutes delay). Strong consistency only when critical (money transfer).

**#. How do you implement data replication and synchronization?**

Services need some shared data but own databases. **Approaches**: **1) Event-Driven Replication** - service publishes events on changes, others listen and update their copy. **2) Change Data Capture (CDC)** - capture database changes (transaction log), publish as events. Tools: Debezium. **3) ETL/ELT** - batch sync periodically. Stale but simple. **4) API Calls** - service queries other service when needed (synchronous). **5) Shared Database** - anti-pattern, avoid. **Example**: product-service owns products. order-service needs product info. **Event-driven**: ProductUpdated event → order-service updates local product cache. **CDC**: Debezium captures product table changes → Kafka → order-service. **API**: order-service calls product-service on each order (real-time but coupling). **Trade-offs**: Events/CDC - eventual consistency, complexity. API - tight coupling, latency. **Best practice**: replicate reference data (products, categories) with events/CDC. Transactional data (orders, users) stays in owning service, query via API if needed. Include version/timestamp for conflict resolution.

**#. What is Change Data Capture (CDC)?**

CDC captures changes in database and streams them as events. Instead of application publishing events, database transaction log is read. **How it works**: **1) Database writes** - changes logged in transaction log (binlog for MySQL, WAL for Postgres). **2) CDC tool** - reads log, converts to events. **3) Publishes** - sends to Kafka or other broker. **4) Consumers** - downstream services consume events. **Tools**: **Debezium** (most popular, supports MySQL, Postgres, MongoDB, etc.), **AWS DMS**, **Google Datastream**, **Oracle GoldenGate**. **Benefits**: **1) Guaranteed Events** - every change becomes event, no missing events. **2) No Code Changes** - application doesn't publish events, CDC does. **3) Ordering** - maintains transaction order. **4) Initial Snapshot** - can capture existing data. **Use cases**: **1) Event Sourcing** - capture all changes. **2) Data Replication** - sync to data warehouse, Elasticsearch. **3) Cache Invalidation** - update caches on changes. **4) Microservices Integration** - share data without coupling. **Trade-offs**: additional component to manage, database dependency, schema changes need handling. CDC powerful for data replication without code changes.

**#. How do you handle shared reference data?**

Reference data: relatively static, shared across services (products, categories, countries). **Anti-pattern**: shared database - breaks service independence. **Approaches**: **1) Duplicate Data** - each service has own copy, updated via events. Most common. **2) Reference Data Service** - dedicated service for reference data, others query it. **3) Read-Only Shared Database** - separate read-only DB, updated from master. **4) Caching** - services cache reference data locally. **Example - Products**: product-service owns products. order-service, inventory-service need product info. **Solution**: ProductUpdated event → services update local copy. Or services cache products, refresh periodically. **Considerations**: **1) Update Frequency** - rarely changing (cache), frequently changing (events). **2) Consistency Needs** - critical (query owner service), non-critical (eventual via events). **3) Volume** - small dataset (replicate), large (query/cache). **4) Query Patterns** - complex queries (local copy), simple lookups (cache/query). **Best practice**: replicate small, stable reference data. Query owner for critical, real-time data. Accept eventual consistency where possible.

**#. What is the Saga pattern's compensating transactions?**

Compensating transactions undo effects of completed transactions when saga fails. Like rollback in distributed context. **Concept**: in monolith, transaction fails → rollback. In microservices, can't rollback across services. Instead, execute compensating actions. **Example Saga**: **Forward flow**: CreateOrder → ReserveInventory → ChargePayment → ShipOrder. **Compensation flow**: if ShipOrder fails → RefundPayment → ReleaseInventory → CancelOrder. Each step has compensating action. **Types**: **Semantic Rollback** - undo business action (refund != delete payment record, it's new compensating transaction). **Compensating Action** - not perfect rollback, may leave traces (audit, analytics). **Implementation**: each saga step stores compensation info. Orchestrator executes compensations in reverse order on failure. **Challenges**: **1) Designing Compensations** - some actions hard to undo (sent email). **2) Failure During Compensation** - retry until succeeds. **3) Consistency** - temporary inconsistency during compensation. **Best practices**: idempotent compensations, monitoring saga state, human intervention for stuck sagas. Compensating transactions enable eventual consistency in distributed transactions.

**#. How do you handle data privacy and GDPR in microservices?**

Data privacy more complex with distributed data. **Challenges**: **1) Data Location** - user data scattered across services. **2) Right to Access** - gather data from all services. **3) Right to Erasure** - delete from all services. **4) Consent Management** - track across services. **Solutions**: **1) Data Catalog** - inventory of where personal data lives. **2) User Data Service** - aggregates user data from all services. **3) Deletion Events** - UserDeleted event → all services delete user data. **4) Anonymization** - replace with pseudonyms for analytics. **5) Encryption** - encrypt personal data at rest and transit. **6) Access Control** - strict RBAC, least privilege. **7) Audit Logging** - log all data access. **Example - Right to Erasure**: user requests deletion → user-service publishes UserDeleted event → order-service anonymizes orders, email-service deletes email, analytics-service removes from warehouse. **Compliance**: document data flows, implement processes, regular audits. **Tools**: data discovery tools, encryption libraries, audit logging. **Best practice**: privacy by design - consider compliance when designing services, minimize data replication, central consent management.

**#. What are polyglot persistence and its implications?**

Polyglot persistence: different microservices use different databases suited to their needs. **Example**: user-service uses Postgres (relational), product-catalog uses MongoDB (document), inventory-service uses Redis (cache), analytics-service uses Cassandra (time-series). **Benefits**: **1) Optimal Tool** - use best database for use case. **2) Technology Freedom** - teams choose tech. **3) No Compromise** - don't force all data into one model. **Challenges**: **1) Operational Complexity** - expertise in multiple databases, different backups/monitoring. **2) Transaction Management** - can't join across databases, can't use distributed transactions. **3) Data Consistency** - eventual consistency across different stores. **4) Learning Curve** - team must learn multiple databases. **5) Tooling** - different tools per database. **When to use**: different data models needed (relational, document, graph), performance requirements vary, teams have expertise. **When not**: small team, simple domain, operational overhead too high. **Best practice**: start with one database (Postgres), add others only when clear benefit. Polyglot powerful but adds complexity - use judiciously.

**#. How do you implement database schema migrations in microservices?**

Schema changes with zero downtime, independent deployments. **Challenges**: **1) Zero Downtime** - can't take database offline. **2) Independent Deployment** - database and service version may mismatch. **3) Rollback** - must support rolling back service without database rollback. **Strategies**: **1) Backward Compatible Changes** - expand schema, don't break old version. Add column with default, both versions work. **2) Multi-Phase Migrations** - Phase 1: add new column, deploy service that writes to both old and new. Phase 2: migrate data. Phase 3: deploy service using only new, remove old column. **3) Database Versioning** - Flyway, Liquibase version schema, migrations in code. **4) Blue-Green Deployment** - deploy new version, switch traffic. **Backward Compatible Examples**: add column (compatible), remove column (break - use multi-phase), rename column (break - add new, write both, migrate, remove old). **Best practices**: only additive changes, test rollback, automate migrations, version migrations with code. **Example**: add email column. Step 1: deploy with default. Step 2: backfill existing rows. Step 3: make not-null. Schema migrations critical for continuous deployment.

**#. What is the Strangler Database pattern?**

Strangler Database gradually migrates data from monolithic database to microservice databases. Parallel to Strangler Fig for application. **Process**: **1) Identify Data** - which data belongs to which service. **2) Create New Database** - setup microservice's database. **3) Dual Writes** - application writes to both old and new database. **4) Data Migration** - batch migrate existing data. **5) Read Switch** - gradually switch reads to new database. **6) Remove Old** - stop dual writes, remove from monolith database. **Example**: monolith with orders table. **Step 1**: create order-service with own database. **Step 2**: dual write - write orders to both databases. **Step 3**: migrate existing orders. **Step 4**: switch order reads to new database. **Step 5**: stop writing to old database. **Challenges**: consistency during migration (dual write race conditions), data mapping (schema differences), transaction boundaries. **Tools**: CDC for replication (Debezium), ETL for migration. **Benefits**: gradual, low-risk, reversible. **Best practice**: strangler database in parallel with strangling application code. Complete data ownership per service.

**#. How do you test data consistency across microservices?**

Testing distributed data consistency challenging. **Test Types**: **1) Integration Tests** - test saga flows, verify all services updated. **2) Contract Tests** - verify data formats between services. **3) Chaos Tests** - inject failures, verify compensation. **4) End-to-End Tests** - test complete flows across services. **Strategies**: **Test Sagas**: trigger saga, inject failure at each step, verify compensation executed, final state correct. **Test Events**: publish event, verify all subscribers processed, check their databases. **Test Eventual Consistency**: trigger update, poll read models, verify eventually consistent. **Example**: create order test - call order-service, wait (eventual), verify inventory-service reduced stock, email-service sent email, analytics-service recorded. **Challenges**: timing (eventual consistency), test data isolation, complex setup. **Tools**: Testcontainers (spin up dependencies), REST Assured (API testing), database assertions. **Best practices**: test happy paths and compensations, use deterministic data, clean up test data, test timeouts and retries, monitor consistency in production.

**#. What is the Database-per-Service pattern's alternative?**

Database-per-Service is ideal but hard. **Alternatives when infeasible**: **1) Schema-per-Service** - logical separation in same database, separate schemas/namespaces. Each service accesses only its schema. **2) Table-per-Service** - even more relaxed, separate tables per service in same schema. Use naming conventions (order_*, inventory_*). **3) Shared Database with API** - shared database but services only access via owning service's API, never directly. **4) Materialized Views** - service owns tables, others have read-only views. **When to use alternatives**: **1) Small Scale** - few services, managing multiple databases overkill. **2) Legacy System** - expensive to separate databases. **3) Tight Data Coupling** - services legitimately need transactional consistency. **4) Skill Gap** - team not ready for distributed data management. **Trade-offs**: lose some independence, gain simplicity. Services still coupled via database. **Migration path**: start with shared database alternative, extract databases as services mature. **Best practice**: even with shared database, enforce logical separation - each service owns tables, no cross-service queries.

**#. How do you handle reporting and analytics across microservices?**

Reporting needs data from multiple services. **Approaches**: **1) Data Warehouse** - ETL from all services to central warehouse (Redshift, BigQuery). Batch processing, analytics there. **2) Event Stream** - all services publish events, stream to warehouse (Kafka → warehouse). **3) API Composition** - reporting service queries multiple services, aggregates. Real-time but slow, tight coupling. **4) CQRS Read Model** - dedicated read model for reporting, updated via events. **5) Service-Specific Reports** - each service has reports, no cross-service. Limited. **Best practice**: **Data Warehouse** for offline analytics, **Event Stream** for real-time. Separate reporting from operational concerns. **Architecture**: Services → Events → Kafka → Streaming (Kafka Streams, Flink) → Warehouse → BI Tools (Tableau, Looker). **Example**: sales report needs orders, products, users. Each service publishes events, synced to warehouse, reports run there. **Considerations**: latency (batch vs real-time), data freshness, cost, query flexibility. Reporting doesn't drive microservices design - operational needs do. Build reporting layer on top.

## Deployment & Operations

**#. What is containerization and why is it important for microservices?**

Containerization packages application with dependencies into isolated unit (container). **Docker** most common. **Benefits for Microservices**: **1) Consistency** - runs same everywhere (dev, staging, prod). **2) Isolation** - services don't interfere, each has own dependencies. **3) Resource Efficiency** - lightweight vs VMs, fast startup. **4) Portability** - move between clouds easily. **5) Scalability** - spin up instances quickly. **6) Versioning** - tag images, rollback easily. **7) Microservices-Friendly** - one service per container. **Dockerfile** defines image: base image, copy code, install dependencies, expose port, run command. **Example**: FROM openjdk:11, COPY app.jar, EXPOSE 8080, CMD java -jar app.jar. **Registry**: Docker Hub, AWS ECR store images. **Orchestration**: Kubernetes manages containers at scale. Containers are foundation for modern microservices - enable consistent, scalable deployments.

**#. What is Kubernetes and why is it used for microservices?**

Kubernetes (K8s) is container orchestration platform - manages containerized applications at scale. **Core Concepts**: **Pod** - smallest unit, one or more containers. **Service** - stable endpoint for pods, load balancing. **Deployment** - manages pod replicas, rolling updates. **ConfigMap/Secret** - configuration/secrets. **Ingress** - external access, routing. **Namespace** - logical isolation. **Why for Microservices**: **1) Service Discovery** - built-in DNS, services find each other. **2) Load Balancing** - distributes traffic across pods. **3) Auto-Scaling** - scale pods based on CPU/memory. **4) Self-Healing** - restarts failed pods. **5) Rolling Updates** - zero-downtime deployments. **6) Config Management** - externalize configuration. **7) Resource Management** - allocate CPU/memory per service. **8) Multi-Tenancy** - namespaces for environments. **Example**: deploy order-service, Kubernetes creates 3 pods, load balances between them, restarts if crash, exposes via service. **Alternatives**: Docker Swarm (simpler), AWS ECS, Nomad. Kubernetes is industry standard for microservices orchestration.

**#. Explain Kubernetes Pods, Services, and Deployments.**

**Pod**: smallest deployable unit, one or more containers sharing network/storage. Typically one container per pod. Ephemeral - deleted and recreated. Example: order-service pod with app container. **Service**: stable network endpoint for pods. Pods come and go, IPs change. Service provides constant IP/DNS. Load balances across pods. Types: **ClusterIP** (internal), **NodePort** (external via node), **LoadBalancer** (cloud load balancer). Example: order-service Service at order-service.default.svc.cluster.local, routes to order-service pods. **Deployment**: manages pod lifecycle. Defines desired state (3 replicas), ensures actual matches. Handles rolling updates, rollbacks. Example: order-service Deployment specifies 3 replicas, K8s ensures 3 pods running. Update image → Deployment rolls out new version gracefully. **Workflow**: define Deployment (image, replicas) → creates Pods → define Service (selector matching pods) → Service routes traffic. Deployments manage Pods, Services expose them. These three are core Kubernetes abstractions.

**#. What are the different deployment strategies for microservices?**

Strategies for deploying new versions: **1) Recreate** - stop all old, start all new. Downtime. Simple. **2) Rolling Update** - gradually replace instances, one by one. Zero downtime. Default in K8s. **3) Blue-Green** - two environments (blue=old, green=new), switch traffic at once. Instant rollback. **4) Canary** - deploy new to subset (5%), monitor, gradually increase. Minimal risk. **5) A/B Testing** - route specific users to new version, compare metrics. **Example - Canary**: deploy v2 to 5%, monitor errors/latency, if good → 25% → 50% → 100%. If bad → rollback to v1. **Implementation**: **K8s**: rolling update built-in. **Canary**: Istio/Flagger, traffic splitting. **Blue-Green**: two deployments, switch Service selector. **Best practices**: automate deployments (CI/CD), monitor during rollout, define success metrics (error rate < 1%), quick rollback. **Choosing**: rolling for regular updates, canary for risky changes, blue-green for instant rollback needs. Canary most common for microservices.

**#. How do you implement CI/CD for microservices?**

CI/CD automates build, test, deploy. Essential for many services. **CI (Continuous Integration)**: **1) Code Commit** - push to Git. **2) Build Trigger** - GitHub Actions, Jenkins, GitLab CI triggers. **3) Build** - compile, create Docker image. **4) Unit Tests** - run tests. **5) Push Image** - to Docker registry. **CD (Continuous Deployment)**: **6) Deploy to Dev** - automatically deploy to dev environment. **7) Integration Tests** - test in dev. **8) Deploy to Staging** - manual or automatic. **9) Smoke Tests** - basic checks. **10) Deploy to Production** - canary or rolling update. **Pipeline Example**: commit → build image → test → push to ECR → deploy to K8s dev → integration test → deploy to staging → approval → canary deploy to prod. **Per Service**: each microservice has own pipeline, deploys independently. **Tools**: GitHub Actions, Jenkins, GitLab CI, CircleCI, AWS CodePipeline, ArgoCD (GitOps). **Best practices**: fast pipelines (< 10 min), automated tests, versioned images, rollback capability, deployment visibility.

**#. What is GitOps and how does it apply to microservices?**

GitOps uses Git as single source of truth for infrastructure and application config. Changes via pull requests, automated deployment. **Principles**: **1) Declarative** - desired state in Git (YAML). **2) Versioned** - Git history is audit trail. **3) Automated** - tools sync Git to cluster. **4) Observed** - detect and correct drift. **Workflow**: **1) Define** - Kubernetes manifests in Git. **2) Change** - modify YAML, create PR. **3) Review** - team reviews PR. **4) Merge** - PR merged. **5) Automated Deployment** - GitOps tool (ArgoCD, Flux) detects change, applies to cluster. **Benefits**: **1) Audit Trail** - all changes in Git. **2) Rollback** - git revert. **3) Collaboration** - PR reviews. **4) Disaster Recovery** - cluster state in Git. **5) Consistency** - Git is truth, cluster matches. **Tools**: ArgoCD, Flux, Jenkins X. **Example**: update order-service image in Git, ArgoCD detects, applies to K8s. **Microservices**: each service has manifests in Git, independent deployment. GitOps increasingly popular for Kubernetes.

**#. How do you handle configuration management in microservices?**

Configuration: database URLs, API keys, feature flags. Challenges: many services, multiple environments. **Approaches**: **1) Environment Variables** - simple, 12-factor app principle. **2) ConfigMaps/Secrets (K8s)** - store config in K8s. **3) Config Server** - Spring Cloud Config, centralized config in Git. **4) Secret Management** - HashiCorp Vault, AWS Secrets Manager for sensitive data. **5) Service Mesh** - Istio ConfigMap for traffic config. **Best practices**: **1) Externalize** - never hardcode. **2) Separate per Environment** - dev, staging, prod configs. **3) Encrypt Secrets** - use secret management, not plain text. **4) Version** - track config changes. **5) Centralize** - one place to manage, update without redeployment. **Example - Spring Cloud Config**: services read config from config server on startup, config stored in Git repo, change config → services refresh (via actuator or restart). **Kubernetes**: ConfigMap for non-sensitive (DB name), Secret for sensitive (password), mount as env vars or files. Don't commit secrets to Git.

**#. What are the different types of testing for microservices?**

Testing pyramid for microservices: **1) Unit Tests** - test individual functions, mocked dependencies. Fast, many tests. **2) Integration Tests** - test service with database, message broker. Real dependencies. **3) Contract Tests** - verify service contracts (Pact). Prevent breaking changes. **4) Component Tests** - test single service with mocked external services. **5) End-to-End Tests** - full flow across multiple services. Slow, expensive. Few tests. **6) Load Tests** - performance under load. **7) Chaos Tests** - inject failures, test resilience. **Test Types by Scope**: **In-Process**: unit tests. **Out-of-Process**: integration tests (database, message broker). **Cross-Service**: contract, E2E tests. **Best practices**: **1) Test Pyramid** - many unit, fewer integration, few E2E. **2) Independent** - services test independently. **3) Test Doubles** - mock external dependencies. **4) Consumer-Driven Contracts** - consumers define expected API. **5) Production-like Environment** - staging should mimic prod. **Balance**: E2E tests catch integration bugs but slow and flaky. Contract tests provide confidence faster.

**#. What is contract testing and why is it important?**

Contract testing verifies service provider and consumer agree on API contract. Prevents breaking changes. **Problem**: order-service expects {orderId, userId}. payment-service changes to {id, user}. Order-service breaks. No visibility until runtime. **Solution - Contract Testing**: **1) Consumer defines contract** - expected request/response. **2) Provider verifies** can fulfill contract. **3) Automated** - tests run on CI. **Tools**: **Pact** (most popular), **Spring Cloud Contract**. **Flow**: **Consumer**: define expectation (GET /orders/123 returns {orderId, userId}), generate Pact file (contract). **Provider**: verify against Pact, if breaks, test fails. **Benefits**: **1) Independent Development** - teams develop in parallel. **2) Catch Breaks Early** - before integration. **3) Documentation** - contract documents API. **4) Confidence** - safe to deploy independently. **Example**: order-service (consumer) defines expects orderId field. payment-service (provider) runs tests, if removed orderId, test fails. **Best practice**: consumer-driven contracts, version contracts, run in CI. Contract testing critical for microservices communication confidence.

**#. How do you implement blue-green deployment?**

Blue-green deployment runs two identical production environments, switches traffic instantly. **Setup**: **Blue** (current production), **Green** (new version), **Router** (directs traffic). **Process**: **1) Deploy to Green** - deploy new version to green environment while blue serves traffic. **2) Test Green** - smoke tests, verify functionality. **3) Switch Traffic** - router redirects all traffic from blue to green. Instant cutover. **4) Monitor** - watch metrics, errors. **5) Rollback** - if issues, switch back to blue. **6) Cleanup** - if successful, blue becomes standby for next deployment. **Implementation**: **K8s**: two Deployments (blue, green), Service selector points to blue, switch selector to green. **Load Balancer**: AWS ELB switches target group. **Istio**: VirtualService routes traffic. **Benefits**: zero downtime, instant rollback, test in production-like environment. **Challenges**: expensive (double resources), database migrations tricky (both versions must work with same schema). **Best for**: critical services, when confident in new version, need instant rollback. Use canary for gradual rollout.

**#. What is a canary deployment?**

Canary deployment gradually rolls out new version to subset of users, monitors, and expands or rolls back. **Process**: **1) Deploy Canary** - deploy new version alongside old (e.g., 5%). **2) Route Traffic** - 5% users get new version, 95% get old. **3) Monitor** - watch error rate, latency, business metrics. **4) Expand** - if good, increase to 25%, 50%, 75%, 100%. **5) Rollback** - if bad, route all traffic back to old. **Implementation**: **Istio/Flagger**: define traffic split, Flagger automates progressive rollout based on metrics. **K8s**: two Deployments, Service routes based on weight. **AWS/GCP**: load balancer weighted routing. **Example**: deploy order-service v2, route 5% traffic, if error rate normal → 25% → 50% → 100%. If errors spike, rollback. **Benefits**: low risk (small blast radius), real user testing, gradual rollout. **Challenges**: complexity (traffic routing, monitoring), metrics need real-time. **Best practices**: define success criteria (error rate < 0.5%, p99 < 500ms), automate rollout/rollback, start small (1-5%). Canary preferred for microservices deployments.

**#. How do you handle zero-downtime deployments?**

Zero-downtime: deploy without service interruption. **Strategies**: **1) Rolling Update** - replace instances gradually, always some instances serving. **2) Blue-Green** - switch traffic to new environment. **3) Canary** - gradual rollout. **Requirements**: **1) Multiple Instances** - at least 2 replicas. **2) Load Balancer** - distributes traffic. **3) Health Checks** - don't route to unhealthy instances. **4) Graceful Shutdown** - finish in-flight requests before stopping. **5) Backward Compatibility** - new version works with old database schema, old API clients. **K8s Rolling Update**: **1) Deploy new version** - K8s creates new pod. **2) Wait for Ready** - health check passes. **3) Add to Service** - receives traffic. **4) Terminate Old** - graceful shutdown, removed from Service. **5) Repeat** - one pod at a time. **Challenges**: database migrations (must be backward compatible), long-running requests (WebSockets), stateful services. **Best practices**: readiness probes, graceful shutdown (SIGTERM handler), rolling deployments, backward-compatible changes. Zero-downtime essential for production microservices.

**#. What is chaos engineering in microservices?**

Chaos engineering tests system resilience by injecting failures intentionally. Assumes systems fail, proactively find weaknesses. **Practice**: **1) Hypothesis** - "if service X fails, system continues". **2) Inject Failure** - kill pods, add latency, drop packets. **3) Observe** - does system handle gracefully? **4) Learn** - identify weaknesses, improve. **Tools**: **Chaos Monkey** (Netflix) - randomly terminates instances. **Gremlin** - chaos engineering platform. **LitmusChaos** - Kubernetes-native. **Istio** - fault injection. **Experiments**: **1) Kill Pods** - random pod deletion. **2) Network Latency** - add delay. **3) Network Partition** - simulate split-brain. **4) Resource Exhaustion** - consume CPU/memory. **5) Dependency Failure** - mock failed external service. **Benefits**: find bugs before users do, validate resilience patterns (circuit breaker, retry), builds confidence. **Example**: kill order-service pod, expect: K8s restarts, traffic routes to healthy pods, no user impact. **Best practices**: start in staging, small blast radius, monitor closely, have rollback plan, gameday exercises. Chaos engineering uncovers hidden failure modes in distributed systems.

**#. How do you implement feature flags in microservices?**

Feature flags control features at runtime without deployment. **Use cases**: **1) Progressive Rollout** - enable for 10% users, expand gradually. **2) Kill Switch** - disable problematic feature instantly. **3) A/B Testing** - enable for specific users, compare. **4) Dark Launch** - deploy code disabled, test in prod. **Implementation**: **1) Flag Service** - centralized service stores flags (LaunchDarkly, Unleash, feature-service). **2) SDK** - services call flag service to check if feature enabled. **3) Targeting** - enable based on user, region, percentage. **Example**: if (featureFlags.isEnabled("new-checkout", userId)) { newCheckout(); } else { oldCheckout(); }. **Types**: **Boolean** (on/off), **Percentage** (10% users), **User-Targeted** (specific users), **Operational** (circuit breaker state). **Best practices**: **1) Centralized** - not per-service config. **2) Audit** - track who changed what. **3) Cleanup** - remove old flags. **4) Performance** - cache flags, async updates. **5) Fallback** - default value if flag service unavailable. Feature flags enable continuous delivery - deploy often, control release separately.

**#. What are the observability requirements for microservices?**

Observability: ability to understand system internal state from external outputs. Critical for distributed systems. **Three Pillars**: **1) Metrics** - quantitative measurements (CPU, memory, request rate, error rate). **2) Logs** - discrete events (request received, error occurred). **3) Traces** - request journey across services. **Metrics**: Prometheus collects, Grafana visualizes. Key metrics: RED (Rate, Errors, Duration) or USE (Utilization, Saturation, Errors). **Logs**: structured logging (JSON), centralized (ELK, Splunk), include correlation ID. **Traces**: distributed tracing (Jaeger, Zipkin), track request across services. **Additional**: **4) Alerts** - notify on anomalies. **5) Dashboards** - visualize health. **6) Service Mesh** - automatic observability. **Example**: request comes in, trace ID generated, each service logs with trace ID, spans sent to Jaeger, metrics to Prometheus, view trace in Jaeger (shows latency per service), metrics in Grafana (shows error spike), logs in ELK (shows error details). **Requirements**: standardization (all services use same format), automation (instrumentation), real-time, correlation. Good observability essential for operating microservices.

## Microservices Patterns & Best Practices

**#. What is the Backend for Frontend (BFF) pattern?**

BFF creates separate backend for each frontend client type (web, mobile, IoT). Each BFF tailored to specific client needs. **Problem**: single generic API doesn't serve all clients well. Mobile needs less data (bandwidth), simpler responses. Web needs more. Desktop different. Trying to satisfy all compromises all. **Solution**: web-bff for web app, mobile-bff for mobile app, etc. Each optimized for its client. **Benefits**: **1) Client-Optimized** - mobile-bff returns minimal data, optimized for mobile. **2) Team Autonomy** - frontend team owns BFF, can change independently. **3) Security** - different auth/permissions per client. **4) API Evolution** - evolve BFF without affecting others. **Implementation**: BFF sits between API Gateway and microservices. BFF makes multiple service calls, aggregates, transforms for client. **Example**: mobile-bff calls user-service, order-service, product-service, returns {user, orders, products} in one response. web-bff returns more detailed format. **Ownership**: frontend team owns BFF. **Trade-offs**: more codebases, data duplication. Worth it when clients have very different needs.

**#. What is the Aggregator pattern?**

Aggregator (or API Composition) pattern composes data from multiple services into single response. **Problem**: client needs data from multiple services. Making multiple requests inefficient, exposes internal architecture. **Solution**: Aggregator service calls multiple services, merges responses, returns to client. **Example**: Order Details needs order (order-service), user (user-service), product (product-service), payment (payment-service). Aggregator calls all, combines into OrderDetails response. **Implementation**: **Sequential** - call services one by one. Slow but simple. **Parallel** - call services concurrently. Faster, more complex. **Reactive** - CompletableFuture, WebFlux for parallel calls. **Challenges**: **Performance** - multiple calls add latency. **Failure Handling** - what if one service fails? Return partial data or fail entire request? **Transactions** - can't guarantee consistency. **Best practices**: call in parallel, timeouts on each call, circuit breakers, cache when possible, return partial data with indicators. **Aggregator vs BFF**: BFF is client-specific, Aggregator is operation-specific. Can combine - BFF uses Aggregator.

**#. What is the Proxy pattern (API Gateway as Proxy)?**

Proxy pattern routes requests to backend services without modification. API Gateway acts as reverse proxy. **Responsibilities**: **1) Routing** - based on URL path. /users/* → user-service, /orders/* → order-service. **2) Protocol Translation** - REST to gRPC, HTTP to WebSocket. **3) Load Balancing** - distribute across instances. **4) SSL Termination** - handle HTTPS, backend uses HTTP. **Benefits**: **1) Single Entry Point** - clients call one URL. **2) Decoupling** - clients don't know internal topology. **3) Cross-Cutting** - auth, rate limiting, logging at proxy level. **Example**: client calls api.example.com/users/123, Gateway routes to user-service:8080/users/123, returns response. **Difference from Aggregator**: proxy is one-to-one (one request → one service), Aggregator is one-to-many (one request → multiple services). **Implementation**: NGINX, Kong, AWS API Gateway, Spring Cloud Gateway. **Pattern**: thin proxy - no business logic, just routing and cross-cutting. Keep simple. Business logic in services, not gateway.

**#. Explain the Event-Carried State Transfer pattern.**

Event-Carried State Transfer includes complete state in event, so consumers don't need to query for details. **Pattern**: **Event Notification** (minimal) - OrderCreated {orderId: 123}. Consumer calls order-service for details. Coupling. **Event-Carried State Transfer** (full state) - OrderCreated {orderId: 123, userId: 456, items: [...], total: 250.00}. Consumer has all needed data, no query needed. **Trade-offs**: **Pros**: decoupling (no synchronous calls), resilience (consumers work even if producer down), performance (no additional calls). **Cons**: larger events, data duplication, event versioning (breaking changes), eventual consistency. **When to use**: consumers need most event data, want to avoid calls, events not too large. **When not**: large payloads (include reference, consumer queries if needed), data changes frequently (becomes stale), privacy concerns (sensitive data in event). **Example**: order-service publishes OrderCreated with full order details. Email-service generates email without calling order-service. Analytics-service stores directly. **Best practice**: include commonly needed data, version events, consumers cache locally.

**#. What is the Saga Orchestration vs Choreography?**

Two ways to coordinate Saga distributed transactions. **Choreography (Event-Driven)**: services react to events, no central coordinator. **Orchestration**: central coordinator tells services what to do. **Choreography Example**: Order-Service publishes OrderCreated → Payment-Service consumes, charges, publishes PaymentCompleted → Inventory-Service consumes, reserves, publishes InventoryReserved → Shipping-Service consumes, ships. Each service knows next step, publishes event. **Orchestration Example**: Saga-Orchestrator creates saga, calls Payment-Service (charge), calls Inventory-Service (reserve), calls Shipping-Service (ship). Orchestrator controls flow. **Choreography Pros**: decoupling (services don't know about each other), scalability. **Cons**: hard to understand flow (no central view), circular dependencies risk, hard to add steps. **Orchestration Pros**: clear flow, easier to understand/debug, centralized control. **Cons**: orchestrator can be bottleneck, services coupled to orchestrator. **Choose**: Choreography for simple flows, fewer steps. Orchestration for complex flows, many steps, need visibility. Most choose orchestration for sagas.

**#. What is the Sidecar Proxy pattern in Service Mesh?**

Sidecar proxy pattern deploys proxy alongside each service, handles all network communication. Foundation of service mesh. **Architecture**: service container + sidecar proxy container (Envoy) in same pod. All inbound/outbound traffic goes through proxy. **Responsibilities**: **1) Service Discovery** - find service instances. **2) Load Balancing** - across instances. **3) Retries** - automatic retry on failure. **4) Circuit Breaking** - stop calling failing service. **5) Timeouts** - enforce timeouts. **6) mTLS** - automatic encryption, authentication. **7) Observability** - metrics, tracing, logs. **Example**: order-service wants to call user-service. Request goes to order's sidecar, sidecar finds user-service instances, load balances, adds mTLS, sends to user's sidecar, sidecar forwards to user-service. All automatic. **Benefits**: zero code changes (service calls localhost), uniform behavior (all proxies configured same), polyglot (works with any language). **Service Mesh**: Istio, Linkerd use sidecar pattern. Control plane configures all sidecars. Data plane (sidecars) handle traffic. Powerful pattern for microservices platform capabilities.

**#. How do you implement rate limiting per user or tenant?**

Rate limiting per entity (user, tenant, API key) to prevent one from consuming all resources. **Implementation**: **1) Identify** - extract identifier from request (user ID from JWT, tenant from header). **2) Counter** - track requests per identifier (Redis: key=user:123, value=count). **3) Check Limit** - if count >= limit, reject (429). **4) Increment** - increase counter. **5) Expire** - counter expires after window (1 hour). **Algorithms**: **Fixed Window** - 100 req/hour, resets at :00. **Sliding Window** - rolling hour. **Token Bucket** - N tokens, requests consume, replenish over time. **Example - Redis**: key = "rate_limit:user:123:2024-03-15-14" (hourly window), increment on each request, check if > 100, if yes return 429, set TTL = 1 hour. **Multi-Tier**: free users 100/hr, paid users 10000/hr. Store tier in user profile, check against tier limit. **Distributed**: use Redis (shared state across instances). **Headers**: return X-RateLimit-Limit, X-RateLimit-Remaining, Retry-After. **Where**: API Gateway (global), or individual services (per-service limits). Critical for fair usage and preventing abuse.

**#. What is the API Versioning strategy for microservices?**

Versioning handles breaking changes while maintaining backward compatibility. **Strategies**: **1) URI Versioning** - /v1/orders, /v2/orders. Most popular, visible. **2) Header Versioning** - Accept-Version: v1. Cleaner URLs. **3) Media Type** - Accept: application/vnd.company.orders.v1+json. Most RESTful. **4) Query Parameter** - /orders?version=1. Less common. **Best Practices**: **1) Semantic Versioning** - MAJOR.MINOR.PATCH. Breaking = major, additions = minor. **2) Support Multiple Versions** - maintain 2-3 versions during transition. **3) Deprecation Policy** - announce 6-12 months in advance. **4) Backward Compatibility** - add fields (don't remove), optional (don't make required). **5) Documentation** - migration guides. **Example**: OrderService v1 {id, items}. v2 adds {id, items, customer, status}. Support both. /v1/orders works (returns id, items), /v2/orders returns all fields. Deprecate v1 after 6 months. **Internal Services**: version less aggressively, consumer-driven contracts instead. **External APIs**: careful versioning, SLAs. Minimize breaking changes.

**#. How do you handle multi-tenancy in microservices?**

Multi-tenancy: single application instance serves multiple tenants (customers), isolated data. **Isolation Levels**: **1) Separate Databases** - each tenant own database. Strongest isolation, expensive, hard to scale. **2) Separate Schemas** - tenants in same database, different schemas. Moderate isolation. **3) Shared Schema** - all tenants in same tables, tenantId column. Weakest isolation, most efficient. **Implementation**: **1) Identify Tenant** - from subdomain (tenant1.app.com), header (X-Tenant-ID), JWT claim. **2) Isolate Data** - filter by tenant in all queries (WHERE tenantId = ?). **3) Security** - ensure no cross-tenant access. **Row-Level Security** (RLS) - database enforces tenant isolation. **Kubernetes**: namespace per tenant, separate deployments. **Challenges**: **1) Query Complexity** - always include tenant filter. **2) Migrations** - apply to all tenants. **3) Performance** - one tenant's load affects others (noisy neighbor). **Best practices**: centralized tenant resolution, tenant context in all operations, audit trail, tenant-aware monitoring. **Example**: tenant from subdomain → tenant service resolves ID → all services filter by tenant ID → data isolated.

**#. What is the Claim Check pattern?**

Claim Check pattern deals with large messages by storing payload separately, passing only reference. **Problem**: large payloads (images, documents) slow messaging, exceed message size limits. **Solution**: **1) Store Payload** - save to blob storage (S3). **2) Send Reference** - message contains only reference (S3 URL). **3) Retrieve** - consumer gets message, fetches payload from storage. **Example**: Order-Service uploads invoice PDF to S3, publishes OrderCreated {orderId: 123, invoiceUrl: "s3://..."}, Email-Service consumes, downloads invoice from S3, sends email with attachment. **Benefits**: smaller messages (faster, cheaper), works with large payloads, message broker not overwhelmed. **Challenges**: additional storage needed, consumer must fetch, eventual consistency (storage may be delayed). **Use cases**: large attachments, binary data, videos/images. **Similar Pattern**: Reference-Based Messaging. **Implementation**: upload to S3/Azure Blob, include URL in message, expiring URLs for security (signed URLs). **Best practice**: for payloads > 100KB, use claim check. Keeps messaging fast and reliable.

**#. How do you implement graceful degradation in microservices?**

Graceful degradation maintains partial functionality when dependencies fail. Opposite: complete failure. **Strategies**: **1) Circuit Breaker** - stop calling failed service, return fallback. **2) Fallback** - return cached data, default value, or reduced functionality. **3) Retry** - retry transient failures. **4) Timeout** - fail fast, don't wait. **5) Bulkhead** - isolate failures. **Example**: product-service calls recommendation-service for "you may also like". Recommendation-service down. Options: **Fail** - product page errors (bad). **Graceful Degradation** - show product page without recommendations (good). **Implementation**: try { recommendations = recommendationService.get(); } catch (Exception e) { recommendations = Collections.emptyList(); }. Or circuit breaker returns fallback (cached recommendations or popular products). **Benefits**: better user experience (partial > none), system resilience (one service failure doesn't cascade). **Challenges**: determining what to degrade, maintaining fallbacks. **Best practice**: identify optional vs critical features, provide fallbacks for optional, monitor degraded state. Graceful degradation improves availability.

**#. What is the Competing Consumers pattern?**

Competing Consumers pattern uses multiple consumers to process messages from queue in parallel, distributing load. **How it works**: **1) Queue** - messages in queue (RabbitMQ, SQS). **2) Multiple Consumers** - multiple instances consume from same queue. **3) Load Balancing** - each message processed by one consumer. **Benefits**: **1) Scalability** - add consumers to increase throughput. **2) Load Distribution** - work shared. **3) Fault Tolerance** - if one consumer fails, others continue. **Example**: OrderCreated events in queue. 5 order-processor instances consume. Each event processed by one instance. **Ordering**: messages processed in parallel, order not guaranteed unless partitioning (Kafka partition per user). **Idempotency**: messages may be redelivered, ensure idempotent processing. **Dead Letter Queue**: failed messages go to DLQ for investigation. **Implementation**: RabbitMQ with multiple consumers, Kafka with consumer group (multiple consumers in group share partitions), AWS SQS with multiple workers. **Use cases**: background jobs, event processing, task queues. Essential pattern for scalable asynchronous processing.

**#. How do you implement the Scatter-Gather pattern?**

Scatter-Gather sends request to multiple services (scatter), aggregates responses (gather). Parallel fan-out and merge. **Use case**: get quotes from multiple suppliers, search across multiple indexes, fetch data from replicas. **Flow**: **1) Scatter** - send requests to N services in parallel. **2) Wait** - for all responses or timeout. **3) Gather** - aggregate responses. **4) Return** - combined result. **Example**: price-comparison service queries 10 suppliers for price, waits for responses (or timeout after 5s), returns aggregated results sorted by price. **Implementation**: **CompletableFuture** (Java), **async/await** (C#), **Promise.all** (JavaScript). Example: List<CompletableFuture<Price>> futures = suppliers.stream().map(s -> CompletableFuture.supplyAsync(() -> s.getPrice(productId))).collect(toList()); CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join(). **Partial Results**: some services may fail, return partial results. **Timeout**: don't wait forever, set deadline. **Circuit Breaker**: don't call known-down services. **Challenges**: latency (slowest determines response time), failure handling, increased load. Use when parallelization saves time.

**#. What are the key principles for designing resilient microservices?**

Resilience: ability to handle and recover from failures. **Principles**: **1) Fail Fast** - detect failures quickly, use timeouts. **2) Fail Independently** - isolate failures (circuit breaker, bulkhead). **3) Degrade Gracefully** - partial functionality > none. **4) Retry Transient Failures** - with exponential backoff. **5) Idempotency** - operations can be safely retried. **6) Asynchronous** - use messaging for decoupling. **7) Stateless** - services don't hold state, easy to restart. **8) Health Checks** - expose health endpoints. **9) Monitor Everything** - metrics, logs, traces. **10) Chaos Engineering** - test resilience proactively. **Patterns**: Circuit Breaker (prevent cascade), Retry (transient failures), Timeout (fail fast), Bulkhead (isolate resources), Fallback (graceful degradation). **Example**: order-service calls payment-service with timeout (5s), circuit breaker (opens after 5 failures), retry (3 times), fallback (return "payment pending"). **Testing**: inject failures, validate handling. **Culture**: assume failures will happen, design accordingly. Resilience is not optional in distributed systems.

**#. What are microservices anti-patterns to avoid?**

Common mistakes: **1) Distributed Monolith** - services tightly coupled (shared DB, synchronous calls everywhere). Microservices without benefits. **2) Nanoservices** - too granular, one method per service. Overhead outweighs benefits. **3) Shared Database** - multiple services access same database. Breaks independence. **4) API Gateway as God Object** - business logic in gateway. Should be thin. **5) Chatty Interfaces** - many calls to complete operation. Network overhead. **6) Wrong Boundaries** - services split along technical (UI, business logic, data) not business lines. **7) No Versioning** - breaking changes without versions. **8) Synchronous Everywhere** - using REST for everything. Should mix sync/async. **9) Ignoring Network** - treating remote calls like local. Network is unreliable. **10) Premature Decomposition** - starting with microservices. Start monolith, extract services when needed. **11) Lack of Automation** - manual deployment of many services. Need CI/CD. **12) No Observability** - can't debug distributed system. **How to avoid**: proper domain modeling (DDD), invest in automation, monitoring, start simple, extract when needed. Avoid cargo cult - microservices because others do. Use when benefits outweigh complexity.
