# REDIS

## Redis Fundamentals

**#. What is Redis and what are its main use cases?**

Redis (Remote Dictionary Server) is an open-source, in-memory data structure store. It's a NoSQL database that stores data in RAM for extremely fast access. **Key characteristics**: in-memory (microsecond latency), data structures (not just key-value), persistence options, single-threaded, supports pub/sub, atomic operations. **Use cases**: **1) Caching** - cache database queries, API responses, session data. **2) Session Store** - web application sessions. **3) Real-time Analytics** - leaderboards, counters, rate limiting. **4) Message Broker** - pub/sub messaging, task queues. **5) Distributed Locks** - coordination across services. **6) Rate Limiting** - track API usage. **7) Full-page Caching** - cache rendered pages. **Why popular**: blazing fast (100k+ ops/sec), flexible data structures, simple to use, battle-tested. **Difference from traditional DB**: optimized for speed over durability (though persistence available), primarily in-memory, limited query capabilities. Redis is often used alongside traditional databases - Redis for hot data, DB for cold data.

**#. What are Redis data types and when do you use each?**

Redis supports multiple data structures: **1) String** - simplest type, binary-safe, up to 512MB. Store: text, numbers, serialized objects. Use: caching, counters (INCR). **2) List** - linked list of strings, ordered. Operations: push/pop from ends (LPUSH, RPOP). Use: queues, activity feeds, recent items. **3) Set** - unordered collection of unique strings. Operations: add, remove, check membership (SADD, SREM, SISMEMBER). Use: tags, unique visitors, relationships. **4) Sorted Set (ZSet)** - like Set but each member has score, sorted by score. Operations: add with score, range queries (ZADD, ZRANGE). Use: leaderboards, priority queues, time-series data. **5) Hash** - field-value pairs, like small objects. Operations: set/get fields (HSET, HGET). Use: user profiles, session data. **6) Bitmap** - bit operations on strings. Use: real-time analytics, user online status. **7) HyperLogLog** - probabilistic counting. Use: unique visitor counts. **8) Streams** - append-only log. Use: event sourcing, message queues. Choose based on access pattern and data structure needs.

**#. Explain Redis persistence mechanisms.**

Redis is in-memory but offers persistence options: **RDB (Redis Database Backup)**: **1) Snapshot** - point-in-time snapshot of dataset. **2) Creation** - manually (SAVE, BGSAVE) or automatic (save 900 1 = save if 1 key changed in 900 sec). **3) Format** - compact binary, fast to load. **4) Pros** - compact, good for backups, fast restart. **5) Cons** - data loss possible (between snapshots), CPU spike during save. **AOF (Append-Only File)**: **1) Log** - logs every write operation. **2) Replay** - replay log to reconstruct data. **3) Fsync policies** - always (slow, safe), everysec (balance), no (fast, risky). **4) Rewrite** - compact AOF when large (BGREWRITEAOF). **5) Pros** - durable (less data loss), readable logs. **6) Cons** - larger files, slower restart. **Hybrid**: RDB + AOF for best of both. **Configuration**: appendonly yes (enable AOF), appendfsync everysec (fsync every second). **Choose**: **RDB** for backups, less critical data. **AOF** for durability. **Both** for production. **No persistence** for pure cache (acceptable data loss).

**#. What is Redis replication and how does it work?**

Redis replication creates copies of data across multiple Redis instances for redundancy and read scaling. **Architecture**: **Master** (primary) handles writes, **Replicas** (slaves) copy data from master, handle reads. **How it works**: **1) Connection** - replica connects to master. **2) Full Sync** - master creates RDB snapshot, sends to replica. **3) Incremental Sync** - master sends write commands to replica. **4) Asynchronous** - replication is async, eventual consistency. **Commands**: REPLICAOF host port (make instance replica of host). **Benefits**: **1) High Availability** - if master fails, promote replica. **2) Read Scaling** - distribute reads across replicas. **3) Disaster Recovery** - replicas in different datacenters. **Limitations**: **1) Async** - replica may lag, stale reads possible. **2) Write Scaling** - doesn't help (only one master). **Configuration**: replica-read-only yes (replicas don't accept writes). **Failover**: manual (REPLICAOF no one promotes replica) or automatic (Sentinel). Production setup: 1 master + 2+ replicas for redundancy.

**#. What is Redis Sentinel?**

Redis Sentinel provides high availability through automatic failover. **Purpose**: monitor Redis instances, automatic failover if master fails, notification, configuration provider. **How it works**: **1) Monitoring** - Sentinels ping master and replicas. **2) Detection** - if master doesn't respond (within timeout), marked as down. **3) Quorum** - majority of Sentinels must agree (configurable quorum). **4) Failover** - elect new master from replicas, reconfigure other replicas. **5) Notification** - notify clients of new master. **Setup**: deploy 3+ Sentinels (odd number for quorum), separate machines from Redis. **Configuration**: sentinel monitor mymaster 127.0.0.1 6379 2 (2 = quorum). **Client support**: clients connect to Sentinel, get current master address. **Benefits**: automatic failover (no manual intervention), monitoring, notifications. **Limitations**: split-brain possible (network partition), eventual consistency. **Use when**: need HA, can tolerate brief downtime during failover. **Alternative**: Redis Cluster for scalability + HA.

**#. What is Redis Cluster?**

Redis Cluster provides horizontal scaling and high availability through sharding. **Architecture**: **1) Sharding** - data split across multiple masters (hash slots). **2) Hash Slots** - 16384 slots, keys hashed to slots, slots assigned to masters. **3) Replication** - each master has replicas. **4) Automatic Failover** - if master fails, replica promoted. **Benefits**: **1) Scalability** - distribute data across nodes, more memory/throughput. **2) High Availability** - replicas provide redundancy. **3) No Proxy** - clients talk directly to nodes. **How it works**: client hashes key, determines slot, connects to node owning slot. If wrong node, redirected (MOVED). **Minimum Setup**: 3 masters + 3 replicas (6 nodes). **Limitations**: **1) Multi-key ops** - only if keys in same slot (use hash tags). **2) No SELECT** - can't use multiple databases. **3) Complexity** - more complex than single instance. **Resharding**: move slots between nodes (online operation). **Use when**: data > single instance RAM, need write scaling, need HA. **vs Sentinel**: Sentinel = HA only, Cluster = scaling + HA.

**#. Explain Redis pub/sub and its use cases.**

Pub/Sub enables message passing between publishers and subscribers via channels. **How it works**: **1) Subscribe** - clients subscribe to channels (SUBSCRIBE channel1). **2) Publish** - clients publish messages (PUBLISH channel1 "hello"). **3) Delivery** - all subscribers receive message. **Commands**: SUBSCRIBE (subscribe to channels), PSUBSCRIBE (pattern-based), PUBLISH (send message), UNSUBSCRIBE. **Characteristics**: **1) Fire-and-forget** - no message persistence, if no subscribers, message lost. **2) At-most-once** - no delivery guarantees. **3) Real-time** - low latency. **Use cases**: **1) Real-time notifications** - chat, notifications. **2) Broadcasting** - system-wide announcements. **3) Event-driven** - microservices communication. **4) Live updates** - dashboards, sports scores. **Limitations**: **1) No persistence** - disconnected subscribers miss messages. **2) No acknowledgments** - can't confirm receipt. **3) No retry** - failed delivery not retried. **Alternative**: Redis Streams for persistent messaging with consumer groups. **Best for**: real-time, ephemeral messages where loss acceptable. Not for reliable messaging (use Kafka, RabbitMQ).

**#. What are Redis transactions and how do they work?**

Redis transactions bundle commands for atomic execution. **Commands**: **MULTI** (start transaction), **EXEC** (execute), **DISCARD** (abort), **WATCH** (optimistic locking). **How it works**: **1) MULTI** - begin transaction, queue commands. **2) Commands** - commands queued, not executed. **3) EXEC** - execute all commands atomically. **Flow**: MULTI → SET key1 value1 → SET key2 value2 → EXEC (both execute atomically). **Characteristics**: **1) Atomic** - all or nothing (but no rollback on error). **2) Isolated** - no other commands interleave. **3) No rollback** - if command fails, others still execute (unlike SQL). **WATCH**: optimistic locking - WATCH key → check/modify → MULTI → EXEC. If key changed after WATCH, transaction aborted. **Use cases**: **1) Atomic updates** - update multiple keys together. **2) Check-and-set** - conditional updates with WATCH. **Limitations**: **1) No rollback** - failed command doesn't rollback others. **2) Blocking** - hold connection during transaction. **Alternative**: Lua scripts for more complex atomic operations.

**#. What are Redis Lua scripts and their benefits?**

Lua scripts enable atomic, complex operations on Redis server. **Usage**: **EVAL** "script" numkeys key1 key2 ... arg1 arg2... **Example**: EVAL "return redis.call('SET', KEYS[1], ARGV[1])" 1 mykey myvalue. **EVALSHA**: execute cached script by SHA hash (more efficient). **Benefits**: **1) Atomicity** - entire script executes atomically. **2) Performance** - no round-trips (command sent once). **3) Complex Logic** - if/else, loops, functions. **4) Reduce Bandwidth** - computation server-side. **Use cases**: **1) Atomic operations** - read-modify-write (increment with max). **2) Rate limiting** - complex rate limit logic. **3) Distributed locks** - Redlock algorithm. **4) Conditional updates** - check-then-set with logic. **Example - Rate Limiting**: check count, increment if < limit, return result - all atomic. **Limitations**: **1) Blocking** - script blocks other commands (keep short). **2) No randomness** - for consistency. **3) Debugging** - harder than application code. **Best practices**: keep scripts short (< 5ms), cache with EVALSHA, test thoroughly. Lua scripts are powerful for operations requiring atomicity and complex logic.

**#. How do you implement caching with Redis?**

Redis excels as cache due to speed. **Patterns**: **1) Cache-Aside (Lazy Loading)** - application checks cache first, on miss queries DB, stores in cache. **2) Write-Through** - write to cache and DB simultaneously. **3) Write-Behind** - write to cache immediately, async write to DB. **Cache-Aside Implementation**: read: check Redis → if miss, query DB → store in Redis → return. Write: update DB → delete/update Redis. **Commands**: GET key (retrieve), SET key value (store), SETEX key seconds value (with TTL), DEL key (evict). **TTL (Time-To-Live)**: EXPIRE key seconds (set TTL), TTL key (check remaining time). Auto-eviction when expired. **Eviction Policies**: maxmemory-policy (noeviction, allkeys-lru, volatile-lru, allkeys-random, volatile-random, volatile-ttl). **LRU** evicts least recently used. **Best practices**: **1) Set TTLs** - prevent stale data. **2) Cache hot data** - frequently accessed. **3) Handle cache misses** - thundering herd (use locks). **4) Invalidation** - delete on updates. **5) Monitoring** - hit rate, memory usage. **Serialization**: JSON or MessagePack for objects.

**#. What is Redis pipelining and when do you use it?**

Pipelining sends multiple commands without waiting for responses, then reads all responses. Reduces round-trip latency. **Normal**: send command → wait → response → send next command → wait → response. **Pipelined**: send command1 → send command2 → send command3 → wait → response1 → response2 → response3. **Example**: Pipeline pipeline = jedis.pipelined(); pipeline.set("key1", "value1"); pipeline.set("key2", "value2"); pipeline.sync(); // execute. **Benefits**: **1) Lower Latency** - reduce round-trips (important for network latency). **2) Higher Throughput** - batch operations. **Use cases**: **1) Bulk operations** - load many keys. **2) Multiple unrelated commands** - independent operations. **Limitations**: **1) Memory** - responses buffered. **2) Not atomic** - commands not transactional (use MULTI for that). **3) Error handling** - must check each response. **vs Transactions**: pipelining = performance, transactions = atomicity. Can combine: pipeline with MULTI/EXEC. **Best practices**: batch 50-100 commands, check for errors, use for independent operations. Pipelining dramatically improves performance over network.

**#. How do you implement rate limiting with Redis?**

Rate limiting restricts requests per user/IP over time. Redis perfect for this due to speed and atomicity. **Approaches**: **1) Counter per Window** - increment counter, reset after window. **2) Sliding Window** - more accurate, track timestamps. **3) Token Bucket** - tokens replenish over time. **Fixed Window Counter**: key = "rate_limit:user123:2024-03-15-14" (hourly window). INCR key, EXPIRE key 3600, check if count > limit. **Sliding Window Log**: ZADD key timestamp timestamp, ZREMRANGEBYSCORE key 0 (now - window), ZCARD key (count), check if count > limit. **Sliding Window Counter** (efficient): combine current + previous window with weights. **Token Bucket with Lua**: script checks tokens, consumes if available, replenishes based on time. **Example - Fixed Window**: limit = 100 req/hour. Key = "limit:user:123:hour:14". If INCR > 100, reject (429). **Best practices**: use Lua for atomicity, distributed (multiple app instances), include user/IP in key, handle edge cases (clock skew). **Alternatives**: Redis Cells module (GCRA algorithm). Rate limiting critical for API protection.

**#. What are Redis streams and how do they differ from lists/pub-sub?**

Redis Streams: append-only log data structure for message streams. **Features**: **1) Append-only** - messages added with unique ID. **2) Consumer Groups** - multiple consumers share load. **3) Acknowledgments** - track message processing. **4) Persistence** - messages stored (unlike pub/sub). **5) Range queries** - read by ID range. **Commands**: XADD (add), XREAD (read), XGROUP CREATE (create consumer group), XREADGROUP (consume), XACK (acknowledge). **vs Lists**: Streams have IDs, consumer groups, better for messaging. Lists simpler, good for simple queues. **vs Pub/Sub**: Streams persist messages, have consumer groups, acknowledgments. Pub/Sub ephemeral, no persistence. **Use cases**: **1) Event sourcing** - store domain events. **2) Message queues** - reliable message processing. **3) Activity feeds** - user activities. **4) Log aggregation** - collect logs. **Example**: XADD mystream * field1 value1 (add message). XREADGROUP GROUP mygroup consumer1 COUNT 10 STREAMS mystream > (consume). Streams provide Kafka-like functionality within Redis.

**#. How do you implement distributed locks with Redis?**

Distributed locks coordinate access to shared resources across multiple processes/servers. **Simple Lock**: SET resource:lock unique_value NX PX 30000 (NX = only if not exists, PX = TTL in ms). Returns OK if acquired, nil if locked. Release: check value matches (ownership), DEL. **Redlock Algorithm** (robust): acquire locks on majority of independent Redis masters. Steps: 1) Get current time. 2) Try to acquire lock on all instances (short timeout). 3) If majority succeed and time < TTL, lock acquired. 4) Release all instances. **Implementation**: SET key unique_value NX PX 30000 on each master, check majority success. **Use cases**: **1) Prevent duplicate processing** - job scheduling. **2) Resource coordination** - single writer. **3) Leader election** - one instance becomes leader. **Challenges**: **1) Clock skew** - TTL based on time. **2) Failure scenarios** - Redis instance crashes. **3) Deadlocks** - always set TTL. **Best practices**: unique lock value (UUID), automatic expiry (TTL), retry logic, use Redlock for critical locks. **Libraries**: Redisson (Java), node-redis-redlock (Node). Distributed locks tricky, use tested libraries.

**#. What is Redis memory optimization?**

Redis stores data in RAM - memory optimization crucial. **Techniques**: **1) Data Structures** - use efficient types (Hashes for small objects, not separate keys). **2) Compression** - shorter key names (user:123 vs u:123). **3) Eviction Policies** - configure maxmemory-policy (LRU, LFU). **4) TTLs** - set expiry, auto-delete. **5) Lazy Freeing** - lazyfree-lazy-eviction yes (async deletion). **Key Naming**: short, meaningful. "usr:123:nm" vs "user:123:name". **Small Objects**: store as hash fields, not separate keys. 100 fields in 1 hash < 100 separate keys (overhead). **Serialization**: JSON, MessagePack, Protobuf for objects. **Monitoring**: INFO memory (used_memory, peak), MEMORY USAGE key (per-key memory). **Eviction**: maxmemory 2gb, maxmemory-policy allkeys-lru (evict LRU when full). **Compression**: Redis 7+ has compression support. **Best practices**: monitor memory, use appropriate data structures, set maxmemory, configure eviction, regular cleanup (SCAN + DEL unused keys). **Tools**: redis-rdb-tools analyze RDB for memory usage. Memory optimization essential as Redis scales.

## Redis Advanced & Operations

**#. How do you monitor Redis performance?**

Monitoring essential for Redis health. **Key Metrics**: **1) Memory** - used_memory, used_memory_peak, maxmemory. **2) CPU** - used_cpu_sys, used_cpu_user. **3) Clients** - connected_clients, blocked_clients. **4) Commands** - instantaneous_ops_per_sec, total_commands_processed. **5) Persistence** - rdb_last_save_time, aof_enabled. **6) Replication** - role (master/replica), connected_slaves, repl_backlog_size. **7) Keyspace** - db0:keys, expires. **8) Hit Rate** - keyspace_hits, keyspace_misses. **Commands**: **INFO** (all stats), **INFO memory** (memory stats), **SLOWLOG GET** (slow commands), **MONITOR** (real-time commands, debug only). **Tools**: **1) Redis-CLI** - INFO, stats. **2) Redis Exporter** - Prometheus metrics. **3) Grafana** - visualization. **4) RedisInsight** - GUI monitoring. **5) Cloud Monitoring** - AWS CloudWatch, Azure Monitor. **Alerts**: memory > 80%, CPU > 70%, replication lag, slow commands. **Best practices**: regular monitoring, set alerts, track trends, capacity planning. Redis monitoring prevents issues before they impact users.

**#. What are Redis slow queries and how do you handle them?**

Slow queries impact performance in single-threaded Redis. **Detection**: **SLOWLOG GET** (retrieve slow commands), **CONFIG SET slowlog-log-slower-than** (threshold in microseconds). **Common causes**: **1) O(N) commands** - KEYS * (scans all keys), SMEMBERS (large set), HGETALL (large hash). **2) Blocking commands** - BLPOP, BRPOP with long timeout. **3) Large values** - large strings, collections. **4) Lua scripts** - long-running scripts. **Optimization**: **1) Use SCAN** - instead of KEYS (non-blocking iteration). **2) Limit sizes** - paginate large collections, use HSCAN/SSCAN/ZSCAN. **3) Async commands** - UNLINK instead of DEL (async deletion). **4) Avoid KEYS in production** - use SCAN or maintain key index. **5) Optimize Lua** - keep scripts short. **Example**: Instead of KEYS user:*, use SCAN 0 MATCH user:*. **Monitoring**: SLOWLOG LEN (count), SLOWLOG GET 10 (last 10). **Best practices**: set slowlog threshold (10ms), review slow queries regularly, refactor O(N) operations, use appropriate data structures. Slow queries in single-threaded Redis block everything.

**#. How do you scale Redis for read and write traffic?**

Scaling strategies differ for reads vs writes. **Read Scaling**: **1) Replication** - add replicas, distribute reads. Load balancer routes reads to replicas. **2) Read-preferring** - clients read from replicas. **3) Caching** - cache results in application layer. **Configuration**: replica-read-only yes, clients use replica addresses. **Write Scaling**: **1) Redis Cluster** - shard data across masters, each handles subset. **2) Application sharding** - manually partition data (by user ID, region). **3) Vertical scaling** - bigger instance (but limited). **Cluster**: 16384 hash slots, keys distributed. More masters = more write capacity. **Challenges**: **1) Replication lag** - reads from replicas may be stale. **2) Cluster complexity** - client support, resharding. **3) Cross-slot operations** - multi-key ops limited in cluster. **Best practices**: **1) Scale reads** - replication (easier). **2) Scale writes** - cluster (more complex). **3) Monitor** - ops/sec, memory, CPU. **4) Plan capacity** - before hitting limits. **5) Application changes** - may need to handle sharding logic. Redis Cluster is solution for write scaling, replication for reads.

**#. What are Redis modules and popular ones?**

Redis Modules extend Redis with new commands and data structures. **How they work**: loaded dynamically (.so files), add new commands, native performance. **Popular modules**: **1) RedisJSON** - native JSON data type, query JSON documents. Commands: JSON.SET, JSON.GET. **2) RediSearch** - full-text search, secondary indexes, aggregations. **3) RedisGraph** - graph database (Cypher queries). **4) RedisTimeSeries** - time-series data, downsampling, aggregations. **5) RedisBloom** - probabilistic data structures (bloom filters, cuckoo filters, count-min sketch). **6) RedisAI** - ML model serving (TensorFlow, PyTorch). **7) RedisGears** - programmable data processing (Python). **Loading**: MODULE LOAD /path/to/module.so or redis-server --loadmodule. **Use cases**: **1) JSON** - store complex objects. **2) Search** - full-text search without external engine. **3) Graph** - social networks, recommendations. **4) TimeSeries** - IoT, metrics. **Benefits**: native performance, integrated with Redis, single platform. **Considerations**: open-source modules (Redis Labs), stability, commercial licensing (some modules). Modules extend Redis beyond key-value store.

**#. How do you backup and restore Redis?**

Backup strategies for Redis data. **RDB Snapshots**: **Manual**: SAVE (blocking) or BGSAVE (background). **Automatic**: configured in redis.conf (save 900 1 = save if 1 key changed in 900 sec). **File**: dump.rdb (binary, compact). **Restore**: copy dump.rdb to data directory, restart Redis (loads automatically). **AOF**: **File**: appendonly.aof (append-only log). **Restore**: Redis replays AOF on restart. **Both**: RDB + AOF for maximum durability. **Best practices**: **1) RDB for backups** - periodic snapshots, copy to S3/backup storage. **2) AOF for durability** - less data loss. **3) Replicas** - backup from replica (don't impact master). **4) Scheduled backups** - cron job BGSAVE, upload to S3. **5) Test restores** - verify backups work. **Cloud**: AWS ElastiCache, Azure Cache auto-backup. **Restore process**: stop Redis, replace dump.rdb/appendonly.aof, start Redis. **Point-in-time recovery**: combine RDB + AOF replay to specific point. Backups critical for disaster recovery.

**#. What are Redis security best practices?**

Redis security often overlooked - essential for production. **Authentication**: **1) PASSWORD** - requirepass in redis.conf, clients AUTH password. Simple but better than nothing. **2) ACLs** (Redis 6+) - per-user permissions, command restrictions. ACL SETUSER alice on >password ~cache:* +get +set. **Network Security**: **1) Bind Address** - bind 127.0.0.1 (localhost only) or specific IPs, not 0.0.0.0 (all interfaces). **2) Firewall** - restrict port 6379 to trusted IPs. **3) VPC** - private network, not internet-exposed. **TLS/SSL**: **1) Encryption in transit** - Redis 6+ supports TLS. **2) Mutual TLS** - client certificates. **Protected Mode**: default, prevents external access without password. **Dangerous Commands**: **1) Rename** - rename-command CONFIG "CONFIG_abc123" (obscure). **2) Disable** - rename-command FLUSHDB "" (disable). **3) Block** - KEYS, FLUSHALL in production. **Best practices**: **1) Never expose Redis publicly** - always private network. **2) Use authentication** - password or ACLs. **3) TLS in transit** - especially across networks. **4) Least privilege** - ACLs for fine-grained access. **5) Monitor** - log access, failed auth attempts. **6) Update** - keep Redis patched. Redis security straightforward but must be configured.

**#. How do you handle Redis failover?**

Failover: switching from failed master to replica. **Automatic Failover**: **1) Redis Sentinel** - monitors master, auto-promotes replica. Setup: 3+ Sentinels (odd number), monitor master. On failure: Sentinels quorum, elect new master, reconfigure replicas. Clients get new master from Sentinel. **2) Redis Cluster** - built-in failover. Each master has replicas. Master fails, replica auto-promoted. **Manual Failover**: **1) Promote replica** - REPLICAOF NO ONE (make replica standalone). **2) Reconfigure** - point other replicas to new master. **3) Update clients** - connect to new master. **Process**: **1) Detect failure** - Sentinel PING timeout or cluster node timeout. **2) Validate** - quorum confirms. **3) Select replica** - best replica (least lag). **4) Promote** - replica becomes master. **5) Reconfigure** - update topology. **6) Notify clients** - clients reconnect. **Data loss**: async replication means some writes may be lost (unacknowledged by replica). **Best practices**: **1) Use Sentinel or Cluster** - for auto-failover. **2) Monitor** - detect issues early. **3) Test failover** - regular drills. **4) Client support** - ensure clients handle failover (reconnect). Failover essential for HA.

**#. What are Redis data eviction policies?**

When Redis hits maxmemory, eviction policy determines what to remove. **Policies**: **1) noeviction** - return errors, don't evict (default, bad for cache). **2) allkeys-lru** - evict least recently used keys. **3) allkeys-lfu** - evict least frequently used (Redis 4+). **4) allkeys-random** - evict random keys. **5) volatile-lru** - evict LRU among keys with TTL. **6) volatile-lfu** - evict LFU among keys with TTL. **7) volatile-random** - evict random among keys with TTL. **8) volatile-ttl** - evict keys with shortest TTL. **Configuration**: maxmemory 2gb, maxmemory-policy allkeys-lru. **LRU vs LFU**: LRU = recent access, LFU = access frequency. LFU better for access patterns with hot keys. **Choosing**: **Cache** (any key can be evicted) - allkeys-lru or allkeys-lfu. **Cache + persistence** (some keys critical) - set TTL on cache keys, volatile-lru. **No eviction** (error on full) - noeviction. **Best practices**: set maxmemory, choose appropriate policy, monitor evictions (evicted_keys metric), set TTLs. Eviction prevents Redis from consuming unlimited memory.

**#. How do you migrate Redis data?**

Migrating data between Redis instances. **Approaches**: **1) MIGRATE command** - atomic move of key(s) to another Redis. MIGRATE host port key destination-db timeout. **2) Replication** - set up replication, promote replica. **3) RDB/AOF transfer** - copy dump.rdb/appendonly.aof, restore on new instance. **4) Scan + Restore** - SCAN keys, DUMP, RESTORE on target. **5) redis-cli --pipe** - bulk load from file. **Replication method**: **1) Setup** - new instance replicates from old. **2) Sync** - full sync + incremental. **3) Switch** - promote new instance, update clients. **4) Cleanup** - remove old instance. **Benefits**: minimal downtime, data consistency. **Online migration**: clients write to old, replication syncs to new, switch when synced. **Tools**: **1) redis-shake** - data sync/migration. **2) redis-port** - cross-version migration. **3) riot** (Redis Input/Output Tool) - data import/export. **Considerations**: **1) Downtime** - some methods require downtime. **2) Data volume** - large data takes time. **3) Version compatibility** - test compatibility. **Best practices**: test in staging, schedule maintenance window, monitor progress, have rollback plan. Migration critical for upgrades, cloud moves, scaling.

**#. What is Redis vs Memcached comparison?**

Both in-memory caches, but differences. **Redis**: **1) Data structures** - strings, lists, sets, sorted sets, hashes, streams. **2) Persistence** - RDB, AOF. **3) Replication** - master-replica. **4) Clustering** - Redis Cluster. **5) Pub/Sub** - messaging. **6) Lua scripts** - server-side logic. **7) Single-threaded** - but pipelining, async I/O. **Memcached**: **1) Simple key-value** - only strings. **2) No persistence** - purely in-memory. **3) No replication** - standalone instances. **4) Multi-threaded** - better multi-core utilization. **5) Simpler** - less features, easier to understand. **Performance**: Memcached slightly faster for simple get/set (multi-threaded). Redis faster for complex operations. **Use Redis when**: need data structures, persistence, replication, pub/sub, richer features. **Use Memcached when**: simple cache, multi-threaded performance critical, don't need Redis features. **Reality**: Redis has largely replaced Memcached (more features, active development). Most new projects choose Redis. Both mature, proven technologies.

**#. How do you implement session management with Redis?**

Web application sessions stored in Redis for speed and sharing. **Approach**: **1) Session ID** - generate unique session ID (UUID), store in cookie. **2) Session data** - store in Redis, key = session:SESSION_ID, value = JSON/serialized session. **3) TTL** - set expiry matching session timeout (SETEX key 3600 value). **4) Retrieve** - on request, get session from Redis by ID. **Commands**: SET session:abc123 "{user_id: 456, name: 'John'}" EX 3600. GET session:abc123. **Data structure**: **Hash**: HSET session:abc123 user_id 456 name John, EXPIRE session:abc123 3600. Better for partial updates (HSET field). **Benefits**: **1) Speed** - faster than DB. **2) Scalability** - centralized, multiple app servers share. **3) Expiry** - auto-delete expired sessions. **4) Failover** - with replication/Sentinel. **Integration**: **1) Express** - express-session + connect-redis. **2) Spring** - Spring Session Data Redis. **3) Django** - django-redis. **Best practices**: use hash for structured data, set TTL, hash session IDs (security), monitor memory, use persistent Redis (AOF) for critical sessions. Redis perfect for sessions - fast, shared, auto-expiry.

**#. What are Redis commands to avoid in production?**

Some Redis commands dangerous in production. **Avoid**: **1) KEYS pattern** - O(N), scans all keys, blocks server. Use SCAN instead. **2) FLUSHALL / FLUSHDB** - deletes all data, catastrophic if accidental. Rename/disable. **3) SMEMBERS / HGETALL / LRANGE** - returns entire collection, can be huge, blocks. Use SSCAN, HSCAN, paginate LRANGE. **4) MONITOR** - debugging tool, outputs all commands, heavy performance impact. **5) DEBUG** - internal debugging, crashes Redis. **6) CONFIG** - changes config, can break things. Rename. **7) SHUTDOWN** - stops Redis, obvious danger. **8) SAVE** - blocking save, freezes Redis. Use BGSAVE. **Mitigation**: **1) Rename** - rename-command FLUSHALL "" (disable) or rename to secret. **2) ACLs** - Redis 6+ restrict commands per user. **3) Read-only replicas** - clients can't modify. **4) Monitoring** - SLOWLOG catches expensive commands. **Best practices**: educate team, use SCAN not KEYS, paginate large collections, disable dangerous commands, use ACLs. **Development**: OK to use KEYS, MONITOR in dev/test. Production: discipline required.

**#. How do you implement caching strategies with Redis?**

Different caching patterns for different needs. **Cache-Aside (Lazy Loading)**: **Read**: check cache → miss → query DB → store cache → return. **Write**: update DB → invalidate cache. **Pros**: only caches requested data. **Cons**: cache miss penalty, stale data possible. **Read-Through**: cache handles DB queries transparently. **Write-Through**: write to cache and DB synchronously. **Pros**: cache always consistent. **Cons**: every write hits both (slower), cache may fill with unused data. **Write-Behind (Write-Back)**: write to cache, async write to DB. **Pros**: fast writes. **Cons**: data loss risk (cache failures), complexity. **Refresh-Ahead**: proactively refresh expiring hot keys. **Pros**: reduce misses. **Cons**: complexity, wasted refreshes. **Choosing**: **Most common**: Cache-Aside for simplicity, balance. **High write load**: Write-Behind for performance. **Read-heavy**: Read-Through for consistency. **Best practices**: **1) TTL** - set expiry (SETEX). **2) Invalidation** - delete on update. **3) Warming** - pre-populate cache. **4) Monitoring** - hit rate, evictions. **5) Serialization** - JSON, MessagePack. Pattern depends on read/write ratio, consistency needs, performance requirements.

**#. What are Redis Sorted Sets use cases and operations?**

Sorted Sets (ZSets): unique members with scores, sorted by score. **Operations**: **ZADD** key score member (add), **ZREM** key member (remove), **ZRANGE** key start stop (range by rank), **ZRANGEBYSCORE** key min max (range by score), **ZRANK** key member (rank), **ZSCORE** key member (get score), **ZINCRBY** key increment member (increment score), **ZCARD** key (count), **ZCOUNT** key min max (count in score range). **Use cases**: **1) Leaderboards** - game scores, user rankings. ZADD leaderboard 1000 user1, ZREVRANGE leaderboard 0 9 (top 10). **2) Priority queues** - tasks with priority. **3) Time-series** - events with timestamp. ZADD events timestamp event_data. **4) Rate limiting** - sliding window (timestamp as score). **5) Autocomplete** - prefix search with scores. **6) Trending** - articles with scores based on votes/time. **Example - Leaderboard**: ZADD scores 100 alice 200 bob, ZREVRANGE scores 0 -1 WITHSCORES (all users sorted). **Operations complexity**: most O(log N), efficient even for millions of members. **Advantages**: automatic sorting, range queries, atomic score updates. Sorted Sets powerful for ranking and time-based data.

**#. What are Redis best practices summary?**

Comprehensive Redis best practices: **Architecture**: **1) Replication** - 1 master + 2 replicas minimum. **2) Sentinel/Cluster** - for HA/scaling. **3) Persistence** - RDB + AOF for production. **Configuration**: **1) Maxmemory** - set limit, configure eviction. **2) Password** - always set, or use ACLs. **3) Bind address** - localhost or specific IP, not 0.0.0.0. **4) Rename dangerous commands** - KEYS, FLUSHALL. **Data modeling**: **1) Efficient structures** - hashes for objects, ZSets for rankings. **2) Short key names** - save memory. **3) TTLs** - set expiration. **Operations**: **1) SCAN not KEYS** - non-blocking iteration. **2) Pipelining** - batch operations. **3) Lua scripts** - atomic complex ops. **Monitoring**: **1) Memory** - used_memory, evictions. **2) Hit rate** - keyspace_hits / (hits + misses). **3) Slow log** - track expensive queries. **4) Replication lag** - master_repl_offset - slave_repl_offset. **Security**: **1) Private network** - never public. **2) Authentication** - password or ACLs. **3) TLS** - encrypt in transit. **Testing**: load test, failover drills, backup/restore tests. **Performance**: monitor, optimize, scale proactively. Following these practices ensures reliable, performant Redis deployment.
